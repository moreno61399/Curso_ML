{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "685da8cc6ae113a2fe70b84f3f00f7c3",
     "grade": false,
     "grade_id": "cell-408e538ba08f800b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Práctica: Integración, normalización y detección de outliers para el algoritmo KNN\n",
    "\n",
    "- [Pre-Procesamiento](#Pre-Procesamiento)\n",
    "- [Problemas de regresión con el algoritmo KNN](#Problemas-de-regresión-con-el-algoritmo-KNN)\n",
    "- [Problemas de clasificación con el algoritmo KNN](#Problemas-de-clasificación-con-el-algoritmo-KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b7598612ca35ef34398c9d686545b5d",
     "grade": false,
     "grade_id": "cell-c5da829f49cc880b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26b21f9d31eacb0c6869e38f06ca084e",
     "grade": false,
     "grade_id": "cell-2b4c5d8a2759d53b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Pre-Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d7ef0fd000aa0d6f4bd3662df8ea9",
     "grade": false,
     "grade_id": "cell-ec5ce108de969831",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En esta primera parte de la práctica vamos a trabajar con un problema de regresión. En concreto vamos a trabajar con el problema de la predicción del valor de una casa en base a su superficie y a su número de habitaciones. \n",
    "\n",
    "Para ello tenemos dos ficheros con históricos de casas:\n",
    "* El primero es ex4data1.txt y contiene casas cuya superficie está medida en pies cuadrados junto con su número de habitaciones y la valoración.\n",
    "* El segundo es ex4data2.txt y contiene casas cuya superficie está medida en metros cuadrados junto con su número de habitaciones y la valoración.\n",
    "\n",
    "Leer los datos almacenados en ambos ficheros mediante la función loadtxt de NumPy. Almacenar los datos en dos variables diferentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9e324ff3043358700e25c22d8d2c715",
     "grade": false,
     "grade_id": "cell-46f046a62fe78c8a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# datos = #<RELLENAR>\n",
    "# datos2 = #<RELLENAR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "689fb810a15e08403d564be801fc37bd",
     "grade": false,
     "grade_id": "cell-270875700b95778a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Según la descripción del contenido de los ficheros podemos ver que existe un problema de escala ya que unas casas están medidas en pies cuadrados y otras en metros cuadrados. Un metro cuadrado equivale a 10,7639 pies cuadrados. \n",
    "\n",
    "Realiza una función que reciba un dataset y el índice de la columna (variable) a tratar. La función debe devolver el dataset en el que los datos de la columna correspondiente han sido transformados de pies cuadrados a metros cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42b9f8abaa04574fab9b45da705acc8c",
     "grade": false,
     "grade_id": "cell-6af4c27810c647d3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def transformaSuperficie(datos, columna):\n",
    "    datosEscalados = np.copy(datos)\n",
    "    #<RELLENAR>\n",
    "\n",
    "    return datosEscalados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "becb0dea0fce2b0b812eb6c87c77bb4b",
     "grade": false,
     "grade_id": "cell-1b0b226a11599b75",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Implementa una función que realice la integración de los dos conjuntos de datos anteriores y devuelva un solo conjunto de datos con los datos en la escala correcta.\n",
    "\n",
    "La función vstack de numpy concatena arrays de forma vertical. Recibe como parámetro de entrada una tupla con los arrays a concatenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49573c988692d0f8b58b267720fd1f64",
     "grade": false,
     "grade_id": "cell-fc8b5b8f945e50d3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def integracion(datos, datos2):\n",
    "    # transormar los datos del primer conjunto de datos\n",
    "#     datosEscalados = #<RELLENAR>\n",
    "\n",
    "    # concatenar los dos conjuntos de datos\n",
    "#     datosAux = #<RELLENAR>\n",
    "\n",
    "    return datosAux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d30cbf163fc3b9395b6fd86d19d9584",
     "grade": false,
     "grade_id": "cell-78a26deef8e5e464",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "También se puede observar que el rango de las dos variables es muy diferente. Por este motivo se debe realizar un proceso de normalización de los datos para que todas las variables de entrada tengan el mismo rango y, por tanto, la misma importancia.\n",
    "\n",
    "Vamos a realizar dos formas de relizar la normalización. La primera de ellas es el método basado en la media y la desviación estándar. Se debe implementar una función que realice el siguiente proceso:\n",
    "* Calcular la media de los valores de todas las variables para todas las instancias\n",
    "* Calcular la desviación estándar de los valores de todas las variables para todas las instancias\n",
    "* A cada valor se le debe restar la media y el resultado dividirlo por la desviación estándar\n",
    "* Devolver los datos normalizados así como las medias y las desviaciones estándar calculadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce79c17305f58f1c496c5924508a1d3a",
     "grade": false,
     "grade_id": "cell-bcdee77788381452",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def normalizarMediaStd(datos):\n",
    "    datosEstandarizados = np.copy(datos)\n",
    "#     media = #<RELLENAR>\n",
    "#     desv = #<RELLENAR>\n",
    "#     datosEstandarizados = #<RELLENAR>\n",
    "\n",
    "    return datosEstandarizados, media, desv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "081462f1bf116afbd1f3dd780fc314cf",
     "grade": false,
     "grade_id": "cell-586797475681415e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Para normalizar nuevos datos de test se debe realizar el mismo proceso que en el caso anterior pero, como son datos nuevos (datos de test), tenemos que utilizar la media y la desviación estándar obtenidas con los datos de entrenamiento. De esta forma la normalización se realizará para todos los datos en las mismas condiciones. \n",
    "\n",
    "Definir una función que normalice nuevos datos de test. Para ello se aplica la misma ecuación que para la función anterior pero utilizando la media y la desviación estándar pasadas como parámetros de entrada (serán las obtenidas con el conjunto de entrenamiento). La función devuelve los nuevos datos normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f391c1a3db85411acf94ffd815b595c",
     "grade": false,
     "grade_id": "cell-6df3aecf4e9c9575",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def normalizarMediaStdTest(datos, media, desv):\n",
    "    datosEstandarizados = np.copy(datos)\n",
    "#     datosEstandarizados = #<RELLENAR>\n",
    "\n",
    "    return datosEstandarizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c05db4141de14ccd8d1da35affee395",
     "grade": false,
     "grade_id": "cell-fe12c30ae660b9ea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "La librería Scikit-Learn de Python nos provee una clase que realiza un proceso de normalización similar (usa la varianza en lugar de la desviación estándar). Dicha clase está dentro de la librería Preprocessing. La clase en concreto que realiza este proceso es la llamada StandardScaler, cuya información se puede ver en la siguiente URL: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler. \n",
    "\n",
    "Para crear un objeto de esta clase es suficiente con llamar al constructor: preprocessing.StandardScaler(). Esta llamada devuelve un objeto con el que podemos llamar a varios métodos, los que vamos a utilizar son:\n",
    "* fit: recibe como parámetro de entrada los datos de entrenamiento y calcula la media y la desviación estándar para cada variable. La media queda almacenada en el campo mean_ y la varianza en el campo var_.\n",
    "* transform: recibe como parámetro de entrada los datos a normalizar y devuelve los datos normalizados utilizando los valores aprendidos previamente y almacenados en mean_ y var_.\n",
    "* fit_transform: realiza el proceso de ambas funciones previamente descritas en una sola función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82b115f58e386e6226a81cde636224a8",
     "grade": false,
     "grade_id": "cell-76463841b6c5f6bd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "normalizarScikitPorMedia = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77e6389a57314dc0f9693e9edc275a93",
     "grade": false,
     "grade_id": "cell-ea03a80259386f64",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El segundo método de normalización es el basado en el mínimo y el máximo de los datos de entrenamiento. Se debe implementar una función que realice el siguiente proceso:\n",
    "* Calcular el mínimo de los valores de todas las variables para todas las instancias\n",
    "* Calcular el máximo de los valores de todas las variables para todas las instancias\n",
    "* A cada valor se le debe restar el mínimo y el resultado dividirlo por la diferencia entre el máximo y el mínimo\n",
    "* Devolver los datos normalizados así como los mínimos y los máximos calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32bb99794af99a292e4c1c43ee718b4a",
     "grade": false,
     "grade_id": "cell-05a316dd37249695",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def normalizarMaxMin(datos):\n",
    "    datosEstandarizados = np.copy(datos)\n",
    "#     minimos = #<RELLENAR>\n",
    "#     maximos = #<RELLENAR>\n",
    "#     datosEstandarizados = #<RELLENAR>\n",
    "\n",
    "    return datosEstandarizados, minimos, maximos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5a0ea49a1e298b68d738e4bfa2c2cc0",
     "grade": false,
     "grade_id": "cell-66fa185b124034f9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Definir una función que normalice nuevos datos de test utilizando los mímimos y los máximos. Para ello se aplica la misma ecuación que para la función anterior pero utilizando los mínimos y los máximos pasados como parámetros de entrada (serán los obtenidos con el conjunto de entrenamiento). La función devuelve los nuevos datos normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd2182a5d91bead4755c52c9b4151073",
     "grade": false,
     "grade_id": "cell-62e7d6e0670d5cbd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def normalizarMaxMinTest(datos, minimos, maximos):\n",
    "    datosEstandarizados = np.copy(datos)\n",
    "#     datosEstandarizados = #<RELLENAR>\n",
    "\n",
    "    return datosEstandarizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "387efac14f865d6a2616a129fd278461",
     "grade": false,
     "grade_id": "cell-1ba2882b55cac9b7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "La librería Scikit-Learn de Python también nos provee una clase que realiza este proceso de normalización. La clase en concreto que realiza este proceso es la llamada MinMaxScaler, cuya información se puede ver en la siguiente URL: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler. \n",
    "\n",
    "Para crear un objeto de esta clase es suficiente con llamar al constructor: preprocessing.MinMaxScaler(). Esta llamada devuelve un objeto con el que podemos llamar a los mismos métodos explicados para la clase StandardScaler. En este caso el valor mínimo para cada variable (calculado con la función Fit) queda almacenado en el campo data_min_ y el máximo en el campo data_max_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "484bebb32ed1f03ff7bb75a0da0773e7",
     "grade": false,
     "grade_id": "cell-f0b21fb47b6aee1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "normalizarScikitPorMinMax = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "487033a621b89c21ab704074709bb1db",
     "grade": false,
     "grade_id": "cell-feb7c785357850be",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El último proceso de preparación de datos que vamos a realizar en esta práctica es el de la detección de outliers. Para ello vamos a utilizar el método de la media y la desciación estándard explicado en clase de teoría. \n",
    "\n",
    "Definir una función que reciba los datos sobre los que detectar los outliers, los valores de las medias de todas las variables, los valores de las desviaciones estándar de todas las variables y el valor de la variable k. Esta función debe devolver una lista con los índices de aquellos ejemplos que contengan algún outlier en alguna variable. Recordar que un valor es considerado outlier si:\n",
    "* valor < media - k*desviacionEstandar\n",
    "* valor > media + k*desviacionEstandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8558a36792e518eb42567f24c4bdedf7",
     "grade": false,
     "grade_id": "cell-c3ec551768838512",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def deteccionOutliers(datos, medias, stds, k=2.0):\n",
    "    # lista con los indices de los ejemplos con outliers\n",
    "    indicesOutliers = []\n",
    "    # blucle para recorrer los ejemplos\n",
    "    for i, ejemplo in enumerate(datos):\n",
    "        # bucle para recorrer las variables\n",
    "        for j in range(len(ejemplo)):\n",
    "\n",
    "    return indicesOutliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bfa8a65ceb5abf9691b21f66dddb7ae",
     "grade": false,
     "grade_id": "cell-e0cf98758a1f1a7b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problemas de regresión con el algoritmo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d927f2c0ebc1b72a4f4bbd2eaa3c45fd",
     "grade": false,
     "grade_id": "cell-9e3829a9ec83b776",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "A continuación vamos a aplicar todas las funciones definidas anteriormente para realizar la fase de solucionar el problema de la valoración de las casas. En primer lugar se deben crear las matrices con los datos de entrada y de salida para los dos conjutnos de dato leídos al comienzo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "546b30da41953488edd45b8580cc25dd",
     "grade": false,
     "grade_id": "cell-8c8580776a1d4674",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# datos de entrada y salida del primer fichero\n",
    "# X1 = #<RELLENAR>\n",
    "# y1 = #<RELLENAR>\n",
    "\n",
    "# datos de entrada y salida del segundo fichero\n",
    "# X2 = #<RELLENAR>\n",
    "# y2 = #<RELLENAR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a098ca97b9f686388658e9566a291f3b",
     "grade": false,
     "grade_id": "cell-917b4673f116e57a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Ahora debéis integrar los dos conjuntos de datos para formar un solo conjunto de datos con el que aplicaremos el resto de procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ce95f8865d53079fc1dff25025ee3f",
     "grade": false,
     "grade_id": "cell-00534356d8993875",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# datos de entrada concatenados e integrados\n",
    "# X = #<RELLENAR>\n",
    "\n",
    "# Calcular el número de filas del conjunto de datos integrado\n",
    "numFilas = X.shape[0]\n",
    "# concatenar las salidas de los dos conjutnos de datos\n",
    "y = np.vstack((y1.reshape(-1,1),y2.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a414c699551c452b1544c98f9200f979",
     "grade": true,
     "grade_id": "cell-1712beaedfc24505",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(numFilas, 57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28c766f7c8a9944e3e79aebb415dba09",
     "grade": false,
     "grade_id": "cell-6bea82ccdd9104eb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El siguiente paso es obtener los índices de aquellos ejemplos que contengan outliers. Para ello debéis llamar a la función que normaliza los datos con el método de la media y la desviación estándar para obtener las medias y las desviaciones estándar de cada variable. Después debéis llamar a la función que obtiene los índices de los ejemplos con outliers y almacenarlos en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd4f48362d4f2fdc97507fe2ad83ec52",
     "grade": false,
     "grade_id": "cell-6ce9f77fcef82b63",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Cálculo de las medias y desviaciones\n",
    "# Xnorm, medias, stds = #<RELLENAR>\n",
    "\n",
    "# Llamada a la función que obtiene los índices de los ejemlos con outliers\n",
    "# indicesOutliers = #<RELLENAR>\n",
    "\n",
    "print(indicesOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fc8d38c8321a474d243bfd9afe9e02a",
     "grade": true,
     "grade_id": "cell-9dc20679e5e65606",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda ind: ind, list(indicesOutliers))), [13, 55, 56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c76247f3602efcf93dc521d332d42b2",
     "grade": false,
     "grade_id": "cell-96d66ef70df64a24",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El siguiente paso es tratar los ejemplos que contengan outliers. En este caso, se ha decidido eliminarlos del conjunto de datos. Por este motivo, debéis crear un nuevo conjunto de datos en el que se hayan eliminado los outliers.\n",
    "\n",
    "La función delete de numpy borra filas de un array (np.delete(array, indices, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c359d43d874e310a358802a5da20c98",
     "grade": false,
     "grade_id": "cell-52e8d17bda18c047",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Borrado de los ejemplos con outliers\n",
    "# XsinOutliers = #<RELLENAR>\n",
    "# YsinOutliers = #<RELLENAR>\n",
    "\n",
    "numFilas = XsinOutliers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf7d012d39570ae3dc21ac97ae2cd003",
     "grade": true,
     "grade_id": "cell-aede5ab85c2f8e7e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(numFilas, 54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee021842d96c2ce7e517d685a663ec31",
     "grade": false,
     "grade_id": "cell-4dc80a737a1e7261",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En este momento ya tenemos los datos integrados y sin outliers por lo que podemos aplicar la técnica de aprendizaje automático. En este caso vamos a aplicar el algoritmo de los K vecinos más cercanos para problemas de regresión. La librería Scikit-Learn nos ofrece una implementación de dicho método que está dentro del paquete neighbors y cuya clase específica es KNeighborsRegressor, cuya información se puede consultar en la sigueinte URL: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor\n",
    "\n",
    "Lo primero que se debe realizar es llamar a la función que crea el modelo de regresión. Esta función tiene varios parámetros que determinan el comprtamiento del algoritmo. La llamada al constructor y sus parámetros son los siguientes:\n",
    "\n",
    "modeloRegresion = neighbors.KNeighborsRegressor(n_neighbors  = K, weights = tipoVoto, metric = tipoDistancia, p = r)\n",
    "\n",
    "Los diferentes parámetros de entrada son\n",
    "* n_neighbors = K: número de vecinos a considerar (valor por defecto = 5)\n",
    "* weights = tipoVoto: forma de votar (peso de cada ejemplo cercano). tipoVoto puede tomar los siguientes valores:\n",
    "    * 'uniform': voto por mayoría  (valor por defecto)\n",
    "    * 'distance': voto en función de la inversa de la distancia\n",
    "* metric = tipoDistancia: forma de calcular la distancia entre los ejemplos.  tipoDistancia puede tomar los siguientes valores:\n",
    "    * 'manhattan': distancia de manhattan\n",
    "    * 'euclidean': distancia euclidea\n",
    "    * 'minkowski': distancia de Minkowski (valor por defecto)\n",
    "* r: en caso de utilizar la distancia de Minkowski hay que especificar el valor del parámetro p que se corresponde al exponente r visto en la clase de teoría. r puede cualquier valor, entre ellos:\n",
    "    * r = 1: distancia de manhattan\n",
    "    * r = 2: distancia euclidea (valor por defecto)\n",
    "    \n",
    "Crear el modelo inicial con todos los valores por defecto. Almacenar el modelo en una variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "913ab28be32a4c9ec39b0621f792acee",
     "grade": false,
     "grade_id": "cell-d0dfb24ca8502298",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "modeloReg = neighbors.KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07267989e0b2c9230b1513f086293e68",
     "grade": false,
     "grade_id": "cell-898f5c0c342c3b2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Una vez creado el modelo debemos entrenarlo. Para ello se debe llamar al método fit del objeto creado anteriormente. A dicho método se le deben pasar los datos de entrenamiento (en este caso todos los datos disponibles) tanto de las variables de entrada (sin outliers) como de la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f66cf15f281b2527667f4da72a0e461d",
     "grade": false,
     "grade_id": "cell-c9fba90bd3a43a95",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# modeloReg = modeloReg.fit(#<RELLENAR>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f393eab33a75da88c2a7fcb38256ee82",
     "grade": false,
     "grade_id": "cell-c45966ba24aadebd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Una vez que el modelo está entrenado lo podemos utilizar para realizar predicciones de nuevos datos. Para ello se debe llamar al método predict al que se pasa comp parámetro de entrada los ejemplos a predecir (en este caso vamos a predecir el valor de todas las casas disponibles sin outliers). Guardar el resultado de las predicciones en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a65afe624ccd227a49b04c119904cbe8",
     "grade": false,
     "grade_id": "cell-af615ce3963c1dbf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# predicciones = modeloReg.predict(#<RELLENAR>) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a576d82709c62c69d0a89bb64898177d",
     "grade": false,
     "grade_id": "cell-c9d472bad7efcb29",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En este punto ya tenemos las predicciones de todas las casas por lo que podemos calcular el rendimiento del modelo. Para ello debéis programar la ecuación que calcula el error cuadrático medio de las predicciones realizadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2b7b9fcf304c2e139ddd91ddb4e0c96",
     "grade": false,
     "grade_id": "cell-7947687134b89396",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# error = #<RELLENAR>\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fdfc68e86e8ab90d3ea338ae1779518",
     "grade": true,
     "grade_id": "cell-bec6b5e86b2c5cd8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(error, 2), 3534488808.38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a1dec8ab3938361f5473eee3a0d2abe",
     "grade": false,
     "grade_id": "cell-0ef1d451103e4a14",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "La librería Scikit-Learn ofrece una función que calcula el error cuadrático medio de las predicciones sin tener que calcularlo. Esta clase está dentro del paquete metrics y se llama mean_squared_error. A esta función se le pasa como argumentos de entrada los valores reales de los ejemplos y las predicciones realizadas por el modelo. Obviamente, devuelve el error cuadrático medio de las predicciones realizadas.\n",
    "\n",
    "Utilizar dicha función para calcular el error cuadrático medio de las predicciones realizadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22054ba8b8a777530f49fa1a9f9ca799",
     "grade": false,
     "grade_id": "cell-250f1f2ba4dab1d4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# errorScikit = mean_squared_error(#<RELLENAR>)\n",
    "\n",
    "print(errorScikit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "073128bbb311cbc5e7ef27da1d7a6473",
     "grade": true,
     "grade_id": "cell-403ab1c84bb1ddc8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(errorScikit, 2), 3534488808.38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e5a54756116d32b2f68f7727d0e4588",
     "grade": false,
     "grade_id": "cell-40cf655321a09c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Una vez que sabemos utiizar la librería de Scikit-Learn para aplicar el algoritmo KNN de regresión vamos a estudiar la influencia de la normalización de los datos a la hora de realizar las predicciones. En primer lugar vamos a realizar la normalización por el método de la media y la desviación estándar.\n",
    "\n",
    "Debéis realizar lo siguiente:\n",
    "* Llamar a la función que hemos implementado para normalizar los datos (sin outliers) según este método.\n",
    "* Realizar el aprendizaje con los ejemplos normalizados (K=5)\n",
    "* Realizar la predicción de los ejemplos normalizados\n",
    "* Calcular el error cuadrático medio\n",
    "\n",
    "¿Es mayor o menor que el obtenido sin normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84fcbcbda12781b85343d028c3bfc19b",
     "grade": false,
     "grade_id": "cell-f3f5c30fb2fc1732",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Xnorm, media, desv = #<RELLENAR>\n",
    "modeloReg = neighbors.KNeighborsRegressor()\n",
    "# modeloReg = modeloReg.fit(#<RELLENAR>)\n",
    "# predicciones = modeloReg.predict(#<RELLENAR>) \n",
    "# errorScikit = mean_squared_error(#<RELLENAR>)\n",
    "\n",
    "print(errorScikit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2583a21e30ab42997c9dd62b7e773cd6",
     "grade": true,
     "grade_id": "cell-4c4653fc2b4c6bcc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(errorScikit, 2), 3473398814.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da23ba6526517b55ece8383ed3b12459",
     "grade": false,
     "grade_id": "cell-440c3343c2902b12",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Realizar el mismo proceso que antes pero utilizando la normalización por el máximo y el mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ead28fae170d67417817d6a3ea03d2ad",
     "grade": false,
     "grade_id": "cell-cdd96e3bd66c21fd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Xnorm, minimo, maximo = normalizarMaxMin(#<RELLENAR>)\n",
    "modeloReg = neighbors.KNeighborsRegressor()\n",
    "# modeloReg = modeloReg.fit(#<RELLENAR>)\n",
    "# predicciones = modeloReg.predict(#<RELLENAR>) \n",
    "# errorScikit = mean_squared_error(#<RELLENAR>)\n",
    "\n",
    "print(errorScikit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3300d27fb5d2a3acc7322916c607b58f",
     "grade": true,
     "grade_id": "cell-fd091717ad21e818",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(errorScikit, 2), 3530600295.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b32a2f134721b0dfc726fc70e71d4848",
     "grade": false,
     "grade_id": "cell-c745fc909d3c86d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problemas de clasificación con el algoritmo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a06489d812192e1d2e407202350525e0",
     "grade": false,
     "grade_id": "cell-16e2104dc2e3f468",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En esta segunda parte de la práctica vamos a trabajar con un problema de clasificación. En concreto vamos a trabajar con el problema de la predicción de si un microchip pasa los tests de calidad o no\n",
    "\n",
    "Leer los datos almacenados en el fichero ex4data3.txt mediante la función loadtxt de NumPy. Almacenar los datos en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b080ed296b3d73eb4318330e22209f",
     "grade": false,
     "grade_id": "cell-4c6ef51d2678006c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# datos3 = #<RELLENAR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6cba96b3726fa5ba20f834fbdeb86ab",
     "grade": false,
     "grade_id": "cell-66aa97f80b53e6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Crear la matriz con los datos de entrada (X) y de salida (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0bb1c107a423485a70738fc3dad28c7",
     "grade": false,
     "grade_id": "cell-d91d1b9da096c7b4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# X = #<RELLENAR>\n",
    "# y = #<RELLENAR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8aa2d626849b0832c7e96ae6281559bd",
     "grade": false,
     "grade_id": "cell-d6c0c62377d467ca",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Normalizar los datos de entrada con el método de la media y la desviación estándar ofrecito por la librería Scikit-Learn. Mostrar los valores de los 5 primeros ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da8d965f3f193e69cc3fff6be74b02db",
     "grade": false,
     "grade_id": "cell-4d01fcd890d8847e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "normalizarScikitPorMedia = preprocessing.StandardScaler()\n",
    "# Xnorm = normalizarScikitPorMedia.fit_transform(#<RELLENAR>)\n",
    "\n",
    "print(Xnorm[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c8fe3507fd0203d95de833d2c964707",
     "grade": false,
     "grade_id": "cell-398fb7f45b01f810",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En este caso, al ser un problema de clasificación, debemos aplicar el algotimo KNN para problemas de clasificación. La librería Scikit-Learn nos ofrece una implementación de dicho método que está dentro del paquete neighbors y cuya clase específica es KNeighborsClassifier, cuya información se puede consultar en la sigueinte URL: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "Esta clase funciona exactamente igual que la que soluciona problemas de regresión.\n",
    "    \n",
    "Crear el modelo inicial con todos los valores por defecto. Almacenar el modelo en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "872c40f0b4e39848d7ff3ff9df2f8273",
     "grade": false,
     "grade_id": "cell-11da5035871dd0ed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "modeloClas = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa3d58c657b964a09b7990694820b74d",
     "grade": false,
     "grade_id": "cell-942eeb0e88ba8b48",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El entrenamiento (fit) y la predicción de nuevos ejemplos (predict) se realizan igual que antes.\n",
    "\n",
    "Sin embargo, para obtener el rendimiento del clasificador debemos aplicar otras funciones de la librería metrics. En concreto vamos a aplicar:\n",
    "* accuracy_score: los parámetros de entrada son las clases reales y las predicciones y devuelve el ratio de ejemplos correctamente clasificados.\n",
    "    * URL: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "* confusion_matrix: los parámetros de entrada son las clases reales y las predicciones y devuelve la matriz de confusión.\n",
    "    * URL: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "* classification_report: los parámetros de entrada son las clases reales y las predicciones y devuelve varias medidas de rendimiento como la precisión, el recall, la medida F1 y el soporte (número real de ejemplos de cada clase).\n",
    "    * URL: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "\n",
    "Entrenar el clasificador con los datos normalizados, realizar sus predicciones y mostrar el resultado de las tres funciones de rendimiento anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11e301af6944e28aeeac890e978d549d",
     "grade": false,
     "grade_id": "cell-e3fbd03b019d00d1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Entrenamineto del modelo\n",
    "# modeloClas = #<RELLENAR>\n",
    "# Predicciones de los datos\n",
    "# predicciones = #<RELLENAR>\n",
    "# Cálculo del accuracy\n",
    "# accuracy = metrics.accuracy_score(#<RELLENAR>)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "# Cálculo de la matriz de confusión\n",
    "# matrizConfusion = metrics.confusion_matrix(#<RELLENAR>)\n",
    "\n",
    "print(matrizConfusion)\n",
    "\n",
    "# print metrics.classification_report(#<RELLENAR>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c53c730d0c5e5de3ae189367747a9463",
     "grade": true,
     "grade_id": "cell-e1a9e5e5dd024985",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(accuracy, 5), 0.84746)\n",
    "assert_equal(list(map(lambda ind: ind, list(matrizConfusion.ravel()))), [48, 12, 6, 52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40c446a6c3bf5d6e4504e2792ab67e81",
     "grade": false,
     "grade_id": "cell-d5760ced028a6fc5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Ahora, vamos analizar el efecto de los parámetros del algoritmo KNN en los resultados obtenidos (accuracy rate):\n",
    "* Número de vecinos (parámetro n_neighbors)\n",
    "    * Probar los resultados con 1, 3, 5 y 7 vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "121ab1b46a8b59f501fc387470b0dc41",
     "grade": false,
     "grade_id": "cell-be2221d52a2ac2eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Lista con los accuracies por cada valor k\n",
    "accScikit = []\n",
    "for k in [1,3,5,7]:\n",
    "    # Creación del modelo\n",
    "#     modeloClas = neighbors.KNeighborsClassifier(#<RELLENAR>)\n",
    "    # Entrenamiento del modelo\n",
    "#     modeloClas = #<RELLENAR>\n",
    "    # Predicciones de los datos\n",
    "#     predicciones = #<RELLENAR>\n",
    "    # Cálculo del accuracy rate\n",
    "#     accuracy = #<RELLENAR>\n",
    "    # Se añade el accuracy a la lista\n",
    "#     accScikit.append(accuracy)\n",
    "\n",
    "    # Se muestra el número de vecinos y el accuracy\n",
    "    print(k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa32c2daf1bca3a99c69b93f19d99baa",
     "grade": true,
     "grade_id": "cell-8a0ae49f8ba35b9a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda ind: round(ind, 3), list(accScikit))), [1.0, 0.856, 0.847, 0.831])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a28e0f152fa56a271f3c33fd881215d",
     "grade": false,
     "grade_id": "cell-7ee26825070644c2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Utilizando un número de vecinos igual a 3, vamos a analizar el efecto de la forma de votación.\n",
    "* Tipo de voto (parámetro weights)\n",
    "    * Probar los valores 'uniform', 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87d354446340506f3859a59ee85722c6",
     "grade": false,
     "grade_id": "cell-862998213fac8383",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Lista con los accuracies por cada tipo de voto\n",
    "accScikit = []\n",
    "for tipoVoto in ['uniform', 'distance']:\n",
    "    # Creación del modelo\n",
    "#     modeloClas = neighbors.KNeighborsClassifier(#<RELLENAR>)\n",
    "    # Entrenamiento del modelo\n",
    "#     modeloClas = #<RELLENAR>\n",
    "    # Predicciones de los datos\n",
    "#     predicciones = #<RELLENAR>\n",
    "    # Cálculo del accuracy rate\n",
    "#     accuracy = #<RELLENAR>\n",
    "    # Se añade el accuracy a la lista\n",
    "#     accScikit.append(accuracy)\n",
    "\n",
    "    # Se muestra el tipo de voto y el accuracy\n",
    "    print(tipoVoto, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1e959ca2de7aac01402dd25b03cff72",
     "grade": true,
     "grade_id": "cell-bc53b64c713179d7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda ind: round(ind, 3), list(accScikit))), [0.856, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a853024e55133f9e2416a16c0bc0e39",
     "grade": false,
     "grade_id": "cell-3b842d15d1cec8e4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Utilizando un número de vecinos igual a 3, vamos a analizar el efecto de la forma de votación.\n",
    "* Tipo de distancia (parámetro metric)\n",
    "    * Probar los valores 'manhattan', 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "350b88adf229e6ac85a80042af0c6372",
     "grade": false,
     "grade_id": "cell-1f16fbee2fd5e4bf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Lista con los accuracies por cada tipo de voto\n",
    "accScikit = []\n",
    "for tipoDistancia in ['manhattan', 'euclidean']:\n",
    "    # Creación del modelo\n",
    "#     modeloClas = neighbors.KNeighborsClassifier(#<RELLENAR>)\n",
    "    # Entrenamiento del modelo\n",
    "#     modeloClas = #<RELLENAR>\n",
    "    # Predicciones de los datos\n",
    "#     predicciones = #<RELLENAR>\n",
    "    # Cálculo del accuracy rate\n",
    "#     accuracy = #<RELLENAR>\n",
    "    # Se añade el accuracy a la lista\n",
    "#     accScikit.append(accuracy)\n",
    "\n",
    "    # Se muestra el tipo de distancia y el accuracy\n",
    "    print(tipoDistancia, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "726fb04d02fd151c7e03c73e2cfcb6d3",
     "grade": true,
     "grade_id": "cell-bdb6a773a5b5256f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda ind: round(ind, 3), list(accScikit))), [0.881, 0.856])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2bb929037ff03f1b7342f2dd474cbc02",
     "grade": false,
     "grade_id": "cell-7ed5a5026e570d9c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Por último, vamos a visualizar la frontera de decisión que genera el clasificador KNN. Debéis hacer lo siguiente:\n",
    "* Aprender el clasificador con los datos normalizados utilizando 3 vecinos, y la distancia de Manhattan. (A realizar)\n",
    "* Se crea una nube de puntos con todas las combinaciones entre el mínimo (-0.1) y el máximo (+0.1) con incrementos de 0.02 de las dos variables.\n",
    "* Se realiza la predicción de todos los ejemplos generados.\n",
    "* Se crea la gráfica donde la predicción de cada clase sale en dieferentes colores (contour) y se muestran los ejemplos de entrenamiento (scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d005e2b633fcd3602c0af0bc52e026c1",
     "grade": false,
     "grade_id": "cell-ce23f6ee08a044f7",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "# modeloClas = #<RELLENAR>\n",
    "# Entrenamiento del modelo\n",
    "# modeloClas = #<RELLENAR>\n",
    "\n",
    "\n",
    "#se crea una grñafca para mostrar la superficie de decisión del clasificador aprendido\n",
    "h = .02  # tamaño de avance en el mesh\n",
    "#TAREA: calcula el mínimo (menos 1) y el máximo (más 1) de las variables x e y\n",
    "x_min = Xnorm[:, 0].min() - 0.1\n",
    "x_max = Xnorm[:, 0].max() + 0.1\n",
    "y_min = Xnorm[:, 1].min() - 0.1\n",
    "y_max = Xnorm[:, 1].max() + 0.1\n",
    "\n",
    "# Se crean todas las combinaciones de valores\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "# Se predicen todos los puntos de la superficio de la gráfica con el clasificador aprendido\n",
    "Z = modeloClas.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "#Se muestran los resultados en la gráfica: la función contourf colorea toda la superficie\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8,8))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.5)\n",
    "\n",
    "#Se muestran los datos del problema: la funcion scatter muestra puntos aislados y los colorea en función de su valor\n",
    "plt.scatter(Xnorm[:, 0], Xnorm[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')\n",
    "\n",
    "#se muestra la figura\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

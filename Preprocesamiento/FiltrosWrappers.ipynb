{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "31dea336b21d4e90c9cf802cbe71b1c0",
     "grade": false,
     "grade_id": "cell-d88ff2b5462ad50e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Práctica de selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b6f8f15b41fdabd94b0ca32975b64a4",
     "grade": false,
     "grade_id": "cell-1075029db68b149c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "- [Método basados en filtros](#Método-basados-en-filtros)\n",
    "- [Método basados en wrappers](#Método-basados-en-wrappers)\n",
    "- [Pipelines](#Pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fd7d611be8bf4fa4572b1d9c58e4016",
     "grade": false,
     "grade_id": "cell-3700c3136ef68eeb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Importamos todas las librerías que vamos a utilizar durante la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "630686056ac7edecc9bc6fa0e0bb53a3",
     "grade": false,
     "grade_id": "cell-c88bc2b4f9d1a440",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "debf9b2f05fbae7949f17e43903c462a",
     "grade": false,
     "grade_id": "cell-6fbf586e31073c88",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para desarrollar la práctica vamos a trabajar con el dataset Sonar. Este dataset contiene la información de un sonar (energía en diferentes bandas de frecuencia) para distinguir rocas (R) de minas (M). En concreto el dataset tiene 60 variables numéricas como entrada y la información de 208 ejemplos. Toda la información de este dataset se puede encontrar en la URL: http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1f02e431c0cecdea6722afda4bc49f03",
     "grade": false,
     "grade_id": "cell-f85cdb81b52a5f51",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Una forma habitual de guardar los datos es mediante archivos .csv como es el caso de esta práctica. Para leerlos se puede utilizar la función *read_csv* de la librería *pandas*: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. Una vez leídos podemos dividir los datos en información de entrada y de salida. \n",
    "\n",
    "En caso de que alguna variable tenga valores discretos en muchos casos es necesario transformarlos a valores numéricos. Asignarles etiquetas utilizando una numeración ordinal se puede conseguir fácilmente utilizando la función *factorize* de *pandas*: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html. \n",
    "\n",
    "En el siguiente código se deben leer los datos del problema sonar almacenados en un archivo .csv. En este caso la variable de salida (la última, llamada Type) está codificada con strings puesto que es una variable discreta y, por lo tanto, debéis convertirla a valores numéricos (utilizando una codificación ordinal) para poder aplicar los métodos disponibles en Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5645b2d52a24d0045c7ce5fd8a31ade9",
     "grade": false,
     "grade_id": "cell-bd1ed2c29d689828",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se realiza la lectura del dataset sonar utilizando pandas\n",
    "    # La primera línea contiene los nombres de las variables\n",
    "    # header=None se utilizaría en caso de que no existiera una primera línea con los nombres para las variables\n",
    "\n",
    "# datos = <RELLENAR>\n",
    "\n",
    "# Generamos los datos de entrada y de salida: nos quedamos con las columnas correspondientes y la transformamos a un array de numpy\n",
    "# X = <RELLENAR>\n",
    "# Transformamos la variable de las clases (valores discretos: strings) en valores numéricos de acuerdo a una codificación ordinal\n",
    "# y =  <RELLENAR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7ef77327572f696b918f9a8db0d8d582",
     "grade": false,
     "grade_id": "cell-c8503f252d991107",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Obtención del rendimiento con todas las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f902af8fd338693e603d9476d722cd99",
     "grade": false,
     "grade_id": "cell-538b241d5beb13d4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para comprobar la calidad de las técnicas de selección de variables, en primer lugar vamos a calcular el rendimiento del clasificador KNN (con la configuración por defecto) si utilizamos todas las variables.\n",
    "\n",
    "Para ello debéis aplicar el método hold-out para obtener los conjuntos de entrenamiento y de test (70% de datos para entrenar). Obtener el accuracy rate tanto para el conjunto de entrenamiento como para el conjunto de test.\n",
    "\n",
    "NOTA: Recordar determinar la semilla para garantizar la reproducibilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8e2af617d188a8699c7ac24ac811a82a",
     "grade": false,
     "grade_id": "cell-fe0da3de89b9c601",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importan las 3 librerías necesarias para resolver el ejercicio\n",
    "from sklearn import neighbors, metrics, model_selection\n",
    "\n",
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Lllamada a la función train_test_split y guardado del resultado\n",
    "# X_train, X_test, y_train, y_test = <RELLENAR>\n",
    "\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador, entrenarlo y obtener los resultados de train y test\n",
    "# knn = <RELLENAR>\n",
    "# accTrain = <RELLENAR>\n",
    "# accTest = <RELLENAR>\n",
    "\n",
    "print('El rendimiento en entrenamiento con todas las variables es el {}%'.format(accTrain))\n",
    "print('El rendimiento en test con todas las variables es el {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8493436c178b1e88cd724980a88d1794",
     "grade": true,
     "grade_id": "cell-d5ebd18d4bf6fbc5",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(round(accTrain, 2), 86.21)\n",
    "assert_equal(round(accTest, 2), 68.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "798015cfe4dc4e861a24ca45da84ca75",
     "grade": false,
     "grade_id": "cell-818e35b31c1de00d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Método basados en filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f761fd20b4ba8a076bf6e7e4916038b",
     "grade": false,
     "grade_id": "cell-3614167daafccfd7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La librería scikit-learn nos ofrece una librería para realizar la selección variables. Esta librería se llama feature_selection y toda su información se puede encontrar en la RUL: http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "Para poder utilizar todas las funcionalidades primero debemos importarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ada189ba442a22b2dc8de3580530e4e9",
     "grade": false,
     "grade_id": "cell-a268cfa9e42199ec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la librería de selección de variables\n",
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aee339420c679de69fb785d360d0f09f",
     "grade": false,
     "grade_id": "cell-ef56e41b055b93e0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "En primer lugar vamos a aplicar técnicas basadas en filtros uni-variable. Los filtros uni-variables aplican una medida (habitualmente estadística) que determina la calidad de las variables individuales. Scikit-learn provee tres métricas de calidad de las variables para resolver problemas de clasificación:\n",
    "* Chi cuadrado: función chi2, cuya información se encuentra en la URL http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2\n",
    "* ANOVA: función f_classif, cuya información se encuentra en la URL http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif\n",
    "* Información mutua: función mutual_info_classif, cuya información se encuentra en la URL http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif\n",
    "\n",
    "Para resolver problemas de regresión ofrece\n",
    "* Correlación mutua: función f_regression, cuya información se encuentra en la URL http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression\n",
    "* Información mutua: función mutual_info_regression, cuya información se encuentra en la URL http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression\n",
    "\n",
    "En esta práctica vamos a utilizar solamente las de clasificación. \n",
    "\n",
    "Una vez conocida la calidad de cada variable se deben escoger las mejores. Para ello vimos en las clases teóricas que había varias opciones. La librería Scikit-learn ofrece dos de estas técnicas en forma de clases (con sus campos y sus métodos):\n",
    "* Elegir las k mejores: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n",
    "    \n",
    "    SelectKBest(score_func=funcionCalidad, k=valorK)\n",
    "    \n",
    "    \n",
    "* Elegir las variables en base al percentil (el % de las variables): http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile\n",
    "    \n",
    "    SelectPercentile(score_func=funcionCalidad, percentile=porcentajeVariables)\n",
    "\n",
    "En ambas clases, elegir las k mejores o las que estén en el percentil deseado, en la llamada al constructor se debe especificar:\n",
    "* La medida de calidad (funcionCalidad) de las variables. Es decir, cualquiera de las 3 funciones comentadas anteriormente\n",
    "    * chi2\n",
    "    * f_classif\n",
    "    * mutual_info_classif\n",
    "* El valor del parámetro k (valorK) para el método de las k mejores o el valor del percentil (porcentajeVariables) para el método de selección en base al percentil.\n",
    "\n",
    "En ambas clases disponemos de los mismos métodos para realizar la selección de las variables:\n",
    "* fit: Recibe como parámetro de entrada los datos de entrada (X) y de salida (Y). Esta función aplica la medida de calidad pasada como parámetro de entrada (funcionCalidad) sobre cada variable y establece la importancia de cada una de ellas.\n",
    "* transform: Recibe como parámetro de entrada los datos de entrada (X). Esta función devuelve los datos de entrada con la selección de variables realizada (X'). Es decir, X' tendrá el mismo número de ejemplos pero menor número de variables (solamente las seleccionadas).\n",
    "* fit_transform: Recibe como parámetro de entrada los datos de entrada (X) y de salida (Y). Esta función aplica secuencialmente las dos funciones anteriores.\n",
    "* get_support: esta función devuelve un array de booleanos con tantos elementos como variables. En cada posición tendrá True si la variable asociada ha sido seleccionada y False en caso contrario.\n",
    "* inverse_transform: Recibe como parámetro de entrada los datos de entrada con la selección de variables realizada (X'). Esta función deshace la selección de variables, es decir, devuelve el conjunto de datos original (X)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c369c7aa910e621962ed683189040dab",
     "grade": false,
     "grade_id": "cell-1981b2660ef60360",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Utiliza el método de selección de las k mejores variables seleccionando las 10, 20 y 30 mejores variables aplicando Chi cuadrado como medida de calidad de las variables. Para ello se debe realizar el siguiente proceso:\n",
    "* Realizar la selección de variables utilizando los ejemplos de entrenamiento obtenidos anteriormente.\n",
    "* Utilizar el clasificador KNN con la configuración por defecto para obtener el accuracy rate con los ejemplos de entrenamiento y de test.\n",
    "* Compara los resultados de las diferentes selecciones realizadas y con respecto a los resultados obtenidos al utilizar todas las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "73c91fa1382136528ed68822c9ec798c",
     "grade": false,
     "grade_id": "cell-0eb3822be759c47e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Listas para almacenar los resultados de accuracy en train y test\n",
    "listaAccTrain = []\n",
    "listaAccTest = []\n",
    "for numVar in [10, 20, 30]:\n",
    "    # Se llama al constructor que realiza la selección de las k mejores variables con los parámetros apropiados\n",
    "#     tecnicaSeleccion = <RELLENAR>\n",
    "    # Llamada a la función que aprende los parámetros de la selección de variables a partir de los datos de entrenamiento\n",
    "#     tecnicaSeleccion = <RELLENAR>\n",
    "    # Llamada a la función que transforma los datos de entrenamiento: realiza la selección de variables\n",
    "#     X_train_seleccion = <RELLENAR>\n",
    "    # Llamada a la función que transforma los datos de test: realiza la selección de variables\n",
    "#     X_test_seleccion = <RELLENAR>\n",
    "    # Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador, entrenarlo y obtener los rendimientos en train y test\n",
    "#     knn = <RELLENAR>\n",
    "#     accTrain = <RELLENAR>\n",
    "#     accTest = <RELLENAR>\n",
    "    listaAccTrain.append(accTrain)\n",
    "    listaAccTest.append(accTest)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en entrenamiento'.format(numVar, accTrain))\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en test'.format(numVar, accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9918fea128867112b4e5560c0979d627",
     "grade": true,
     "grade_id": "cell-2e655281ad60a069",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTrain)), [86.90, 88.97, 86.21], 'Valores de accuracy incorrectos')\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [74.60, 76.19, 76.19], 'Valores de accuracy incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1c502307e2964517ec6b6b983662f853",
     "grade": false,
     "grade_id": "cell-1e13d7ce665ac518",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Repetir el ejercicio anterior pero utilizando ANOVA para medir la calidad de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "faf4ff0481f705d63f1f4e130124637a",
     "grade": false,
     "grade_id": "cell-371975d359615397",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# <RELLENAR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d96b40e3a7df6c0c437c8e99436ba863",
     "grade": true,
     "grade_id": "cell-63faad472f86068c",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTrain)), [87.59, 88.28,87.59], 'Valores de accuracy incorrectos')\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [76.19, 84.13,82.54], 'Valores de accuracy incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "119d0b6c1563394e926c7037fe0ef0f6",
     "grade": false,
     "grade_id": "cell-2b7bf96e9468ed75",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Repetir el ejercicio anterior pero utilizando el método del percentil (10%, 20% y 30%) y Chi cuadrado para medir la calidad de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0deb2cbf1baac202fbe599d86eae045f",
     "grade": false,
     "grade_id": "cell-afd928020b8af528",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# <RELLENAR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b8e88d5100a6dc28254c59038f8a7892",
     "grade": true,
     "grade_id": "cell-c2dc45879c0861be",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTrain)), [82.76, 87.59,86.21], 'Valores de accuracy incorrectos')\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [79.37, 77.78,82.54], 'Valores de accuracy incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9caa00e71d9635aa73ae4e689777226f",
     "grade": false,
     "grade_id": "cell-0775aca6c80e1229",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Repetir el ejercicio anterior pero utilizando ANOVA para medir la calidad de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c8ae59a91feb66eb4d94a6467dca6a4a",
     "grade": false,
     "grade_id": "cell-5e74c8d1a27906e9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# <RELLENAR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a571c025bf3d89f37214576ab36891a0",
     "grade": true,
     "grade_id": "cell-8414e7ffcbf5bcf3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTrain)), [80.69, 83.45,86.90], 'Valores de accuracy incorrectos')\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [82.54, 73.02,88.89], 'Valores de accuracy incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "29a828e774c8213583e0a9f3a08c5356",
     "grade": false,
     "grade_id": "cell-a1320c1bff6dc7cd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Método basados en wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a469148e2f1883a5ebfd1bad91eeff5",
     "grade": false,
     "grade_id": "cell-81288b2e46aea856",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La librería Scikit-learn también nos ofrece una clase para poder implementar un Wrapper. Esta clase está dentro de la librería feature_selection y se llama RFE. Toda la información de la clase la podéis encontrar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE\n",
    "\n",
    "Esta clase corresponde al método Sequential Backward Selecion (SBS) explicado en clase de teoría. Es decir, es el método en el que se comienza con todas las variables del problema e iterativamente se va eliminando la peor variable de las que queden. En el caso de la implementación de esta clase lo que se hace es lo siguiente:\n",
    "* Se aprende un clasificador (pasado como parámetro de entrada: clasificador) con todas las variables y se asignan pesos a cada una de las variables.\n",
    "* Se elimina(n) variable(s) (el número de variables a eliminar se pasa como parámetro de entrada: numeroVariablesEliminarEnPaso) cuyos pesos en valor absoluto sean los menores.\n",
    "* Luego se vuelve a entrenar con las variables que queden y se vuelven a calcular los pesos de dichas variables.\n",
    "* Este proceso se repite hasta que se alcance el número de variables a mantener (pasado como parámetro de entrada: numeroVariablesMantener)\n",
    "\n",
    "La llamada al constructor de la clase es la siguiente:\n",
    "\n",
    "    RFE(clasificador, n_features_to_select=numeroVariablesMantener, step=numeroVariablesEliminarEnPaso)\n",
    "    \n",
    "Esta clase tiene varios métodos, entre ellos los mismos que se han explicado para los filtros uni-variables utilizados en la primera parte de la práctica:\n",
    "* fit: Recibe como parámetro de entrada los datos de entrada (X) y de salida (Y). Esta función aplica la medida de calidad pasada como parámetro de entrada (funcionCalidad) sobre cada variable y establece la importancia de cada una de ellas.\n",
    "* transform: Recibe como parámetro de entrada los datos de entrada (X). Esta función devuelve los datos de entrada con la selección de variables realizada (X'). Es decir, X' tendrá el mismo número de ejemplos pero menor número de variables (solamente las seleccionadas).\n",
    "* fit_transform: Recibe como parámetro de entrada los datos de entrada (X) y de salida (Y). Esta función aplica secuencialmente las dos funciones anteriores.\n",
    "* get_support: esta función devuelve un array de booleanos con tantos elementos como variables. En cada posición tendrá True si la variable asociada ha sido seleccionada y False en caso contrario.\n",
    "* inverse_transform: Recibe como parámetro de entrada los datos de entrada con la selección de variables realizada (X'). Esta función deshace la selección de variables, es decir, devuelve el conjunto de datos original (X).\n",
    "\n",
    "NOTA: el clasificador utilizado en el wrapper (evaluación de la importancia de las variables) tiene que actualizar el atributo coef_ de su clase correspondiente. En caso de que no lo haga no se puede utilizar como clasificador para la eliminación secuencial de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eddb92b5d2e3ef4f2dd51594cad3e808",
     "grade": false,
     "grade_id": "cell-6f4833379acaea50",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Utiliza la clase RFE para realizar la selección de variables en el problema de Sonar. Para ello debes utilizar lo siguiente\n",
    "* Como clasificador del Wrapper utiliza la regresión logística con la configuración por defecto.\n",
    "    * Hay que importar la librería linear_model y utilizar la clase LogisticRegression: linear_model.LogisticRegression()\n",
    "* Eliminar una variable cada vez (step=1)\n",
    "* Probar diferentes valores de variables a mantener: 10, 20 y 30\n",
    "\n",
    "Evalúa la calidad de la selección realizada utilizando la regresión logística con la configuración por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c45167446647a9e431e729aae3619245",
     "grade": false,
     "grade_id": "cell-12c6dac9a4b13429",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Listas para almacenar los resultados de accuracy en train y test\n",
    "listaAccTrain = []\n",
    "listaAccTest = []\n",
    "for variablesMantener in [10, 20, 30]:\n",
    "    # Se llama al constructor que realiza la selección de variables en base a la eliminación secuencial de variables\n",
    "        # Utiliza los parámetros adecuados\n",
    "#     tecnicaSeleccion = <RELLENAR>\n",
    "    # Llamada a la función que aprende los parámetros de la selección de variables a partir de los datos de entrenamiento\n",
    "#     tecnicaSeleccion = <RELLENAR>\n",
    "    # Llamada a la función que transforma los datos de entrenamiento: realiza la selección de variables\n",
    "#     X_train_seleccion = <RELLENAR>\n",
    "    # Llamada a la función que transforma los datos de test: realiza la selección de variables\n",
    "#     X_test_seleccion = <RELLENAR>\n",
    "    # Realizamos el proceso para la regresión logística por lo que hay que llamar al constructor de dicho clasificador, entrenarlo y obtener los rendimientos en train y test\n",
    "#     RL = <RELLENAR>\n",
    "#     accTrain = <RELLENAR>\n",
    "#     accTest = <RELLENAR>\n",
    "    listaAccTrain.append(accTrain)\n",
    "    listaAccTest.append(accTest)\n",
    "    print('Manteniendo {} variables se obtiene un accuracy del {}% en entrenamiento'.format(variablesMantener, accTrain))\n",
    "    print('Manteniendo {} variables se obtiene un accuracy del {}% en test'.format(variablesMantener, accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "62898a5716875e666fd764714aadc47d",
     "grade": true,
     "grade_id": "cell-23b9b1491f348531",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTrain)), [76.55, 78.62, 78.62], 'Valores de accuracy incorrectos')\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [80.95, 85.71, 88.89], 'Valores de accuracy incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4518148ed68e3cd700100d3cb8bbb5f5",
     "grade": false,
     "grade_id": "cell-e53f065eee04052d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "250e911605913cf20522805e976a5441",
     "grade": false,
     "grade_id": "cell-e70f538c3a8dbde1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para finalizar la práctica vamos utilizar una clase que nos permite realizar una secuencia de transformaciones a los datos (pre-procesamiento) que finalmente se aplicarán para entrenar un clasificador. Es decir, vamos a crear una composición de varias fases de pre-procesamiento (todas las que queramos) junto con el aprendizaje de un clasificador sin tener que realizarlas independientemente.\n",
    "\n",
    "La clase que nos ofrece esta posibilidad está dentro de la librería Pipeline y la clase tiene el mismo nombre, Pipeline. Toda la información de esta clase la podéis encontrar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\n",
    "\n",
    "La llamada al constructor de esta clase consiste en un conjunto de tuplas del tipo (nombreFase, objeto), cuyo significado es:\n",
    "* nombreFase: string que establece el nombre de la fase. Por ejemplo 'filtroANOVA' o 'clasificadorKNN'\n",
    "* objeto: variable en la que se almacena la llamada al constructor de lo que se desee hacer. Por ejemplo feature_selection.SelectKBest(feature_selection.f_regression, k=5) o neighbors.KNeighborsClassifier()\n",
    "\n",
    "Es decir, si deseáramos combinar ambos procesos deberíamos realizar la siguiente llamada:\n",
    "\n",
    "    combinado = Pipeline([('filtroANOVA', feature_selection.SelectKBest(feature_selection.f_classif, k=5)), ('clasificadorKNN', neighbors.KNeighborsClassifier())])\n",
    "    \n",
    "Hay que destacar que los objetos de todas las fases (excepto de la última) tienen que tener los métodos fit y transform, para que puedan aprender de los datos y transformarlos en consecuencia. El último objeto debe tener el método fit, para aprender de los datos, y el método predict para poder realizar nuevas predicciones. Es decir, el último objeto debe ser un modelo de clasificación o regresión.\n",
    "\n",
    "El objeto combinado, la Pipeline generada, dispone de los siguientes métodos:\n",
    "* fit: Recibe como parámetros de entrada los datos de entrada (X) y de salida (Y). Cada objeto de cada fase aprende en base a dichos datos.\n",
    "* predict: Recibe como parámetro de entrada los datos de entrada (X). Realiza la predicción realizando lo siguiente:\n",
    "    * Primero se aplican las transformaciones de datos por medio de los primeros objetos (llaman a sus respectivas funciones transform)\n",
    "    * Finalmente, se aplica al objeto de la última fase (clasificador o modelo de regresión) para realizar la predicción correspondiente a los datos de entrada (llamada a su método predict). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8004fec1f8a35beed2c7d37173dd1878",
     "grade": false,
     "grade_id": "cell-d2789d576356dd57",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Realizar una Pipeline que combine:\n",
    "* Selección de variables utilizando el filtro de ANOVA en base al percentil (seleccionar el 30% de las variables) \n",
    "    * feature_selection.SelectPercentile(feature_selection.f_classif, percentile=30)\n",
    "* Clasificador KNN\n",
    "    * neighbors.KNeighborsClassifier()\n",
    "\n",
    "Para ello, utiliza los conjuntos de entrenamiento y test generados al comienzo de la práctica utilizando Hold-out.\n",
    "\n",
    "Comprueba que los resultados son los mismos que los obtenidos cuando hemos utilizado por separado ambos objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "783483480f1e3f86a6b13e1cb1b4ff50",
     "grade": false,
     "grade_id": "cell-6c02c697b5868231",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la librería pipeline\n",
    "from sklearn import pipeline\n",
    "\n",
    "# Se crea la Pipeline con las fases deseadas\n",
    "# combo = <RELLENAR>\n",
    "    \n",
    "# Se realiza el aprendizaje de los parámetros de todas las fases de la Pipeline\n",
    "# combo = <RELLENAR>\n",
    "# Se llama a la predicción de la pipeline sobre los datos de entrenamiento\n",
    "# prediccionesTrain = <RELLENAR>\n",
    "# Se calcula el accuracy para los datos de entrenamiento (entre 0.0 y 100.0)\n",
    "# accTrain = <RELLENAR>\n",
    "print('Resultado en entrenamiento: {}%'.format(accTrain))\n",
    "# Se llama a la predicción de la pipeline sobre los datos de test\n",
    "# prediccionesTest = <RELLENAR>\n",
    "# Se calcula el accuracy para los datos de test (entre 0.0 y 100.0)\n",
    "# accTest = <RELLENAR>\n",
    "print('Resultado en test: {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ea05276483ad1c47dc97523c4b56ee7a",
     "grade": true,
     "grade_id": "cell-442d5551e6d0d39d",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(round(accTrain, 2), 86.90, 'Valor de accuracy en train incorrecto')\n",
    "assert_equal(round(accTest, 2), 88.89, 'Valor de accuracy en test incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b52da8de9b3959dd0b4dff94ec321dcd",
     "grade": false,
     "grade_id": "cell-cce751a3df8d43d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Por último, existe la posibilidad de buscar la mejor configuración de todo el proceso combinado. Es decir, del calificador compuesto creado por la Pipeline. Para ello, de forma similar al método visto para clasificación estándar, scikit-learn ofrece una clase llamada *GridSearchCV* dentro de la librería *model_selection* que realiza tal proceso de forma automática.\n",
    "\n",
    "Una vez importado el paquete podemos usar la clase y para ello lo primero que hay que hacer es una llamada al constructor\n",
    "\n",
    "    gs_clf = model_selection.GridSearchCV(clasificadorCompuesto, parametros, n_jobs=1)\n",
    "    \n",
    "Los parámetros de entrada son\n",
    "\n",
    "* clasificadorCompuesto: el objeto con el clasificador compuesto a “optimizar”\n",
    "* parametros: un diccionario con los nombres de los campos como claves y los valores de cada uno de ellos como valor. \n",
    "    * En este caso, al nombre del campo hay que insertarle como prefijo el componente al que hace referencia seguido de dos barras bajas (nombreComponente__campo: [valores]). \n",
    "    * Por ejemplo filtroANOVA __percentile: (10,20,30)\n",
    "* n_jobs: número de procesadores a utilizar para paralelizar (-1 para que use todos)\n",
    "\n",
    "Una vez generado el objeto, el siguiente paso es realizar el aprendizaje. Para ello se llama a la función fit. Este paso y la visualización de la mejor configuración los rendimientos asociados es igual a los vistos para la validación de clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c2a9f3a4dcd90ad61939bc670131a6fe",
     "grade": false,
     "grade_id": "cell-b7fa5c4613bc990b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Utiliza la función GridSearchCV para buscar la configuración óptima del clasificador compuesto por el filtro ANOVA y el clasificador KNN. Los parámetros y valores a optimizar son:\n",
    "* Para la selección de variables basado en el percentil y el filtro ANOVA\n",
    "    * percentile: 10, 20, 30\n",
    "* Para el clasificador KNN\n",
    "    * n_neighbors: 1, 3, 5, 7, 9\n",
    "    * weights: ‘uniform’, ‘distance’\n",
    "    * p: [1, 2, 1.5, 3]\n",
    "\n",
    "NOTAS:\n",
    "* Utiliza todos los ejemplos del dataset sonar (campos data y target) para realizar el entrenamiento.\n",
    "* Utiliza 10 particiones y el accuracy para realizar la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8936630d5259c4b09ac4117849cfe97f",
     "grade": false,
     "grade_id": "cell-a36c8b8237fa15b0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se crea la Pipeline con las fases deseadas\n",
    "# clf_compuesto = <RELLENAR>\n",
    "\n",
    "# Se crea el grid de hyper-parámetros a \"optimizar\"\n",
    "# parameters = <RELLENAR>\n",
    "\n",
    "# Se llama al constructor de GridSearchCV para que genere todas las combinaciones ce los parámetros definidos anteriormente\n",
    "# gridSearch_ClasCompuesto = <RELLENAR>\n",
    "# Se realiza el aprendizaje de todos los clasificadores considerados (todas las configuraciones)\n",
    "# gridSearch_ClasCompuesto = <RELLENAR>\n",
    "\n",
    "# Se muestra la mejor configuración junto con su rendimiento\n",
    "print(gridSearch_ClasCompuesto.best_score_)\n",
    "print(gridSearch_ClasCompuesto.best_params_)\n",
    "\n",
    "# Se muestra el accuracy obtenido para cada posible combinación de parámetros\n",
    "resultadosMostrar = zip(gridSearch_ClasCompuesto.cv_results_['params'],gridSearch_ClasCompuesto.cv_results_['mean_test_score'],gridSearch_ClasCompuesto.cv_results_['mean_train_score'])\n",
    "for params, mean_test_score, mean_train_score in resultadosMostrar:\n",
    "    print(\"%0.3f (Train: %0.3f) for %r\" % (mean_test_score, mean_train_score, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6669746266b402af3fc2d4009b43d64",
     "grade": true,
     "grade_id": "cell-c59b3a9635cea6a1",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(round(gridSearch_ClasCompuesto.best_score_, 4), 0.7212, 'Valor de accuracy en train incorrecto')\n",
    "assert_equal(gridSearch_ClasCompuesto.best_params_, {'KNN__p': 1.5, 'KNN__weights': 'uniform', 'KNN__n_neighbors': 5, 'filtroANOVA__percentile': 20}, 'Mejor configuración incorrecta')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e304ce9e089a3a42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Práctica de análisis de correlaciones y PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4db50fac01ba95c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "- [Análisis de correlaciones](#Análisis-de-correlaciones)\n",
    "- [PCA: Principal component analysis](#PCA:-Principal-component-analysis)\n",
    "- [Pipelines](#Pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17f2d1701252dad3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Importamos todas las librerías que vamos a utilizar durante la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45f1f7699bfcacdb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dada19c167aeec4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para desarrollar la práctica vamos a trabajar con el dataset Sonar. Este dataset contiene la información de un sonar (energía en diferentes bandas de frecuencia) para distinguir rocas (R) de minas (M). En concreto el dataset tiene 60 variables numéricas como entrada y la información de 208 ejemplos. Toda la información de este dataset se puede encontrar en la URL: http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8c62cf942a4903d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Una forma habitual de guardar los datos es mediante archivos .csv como es el caso de esta práctica. Para leerlos se puede utilizar la función *read_csv* de la librería *pandas*: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. Una vez leídos podemos dividir los datos en información de entrada y de salida. \n",
    "\n",
    "En caso de que alguna variable tenga valores discretos en muchos casos es necesario transformarlos a valores numéricos. Asignarles etiquetas utilizando una numeración ordinal se puede conseguir fácilmente utilizando la función *factorize* de *pandas*: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html. \n",
    "\n",
    "En el siguiente código se deben leer los datos del problema sonar almacenados en un archivo .csv. En este caso la variable de salida (la última, llamada Type) está codificada con strings puesto que es una variable discreta y, por lo tanto, debéis convertirla a valores numéricos (utilizando una codificación ordinal) para poder aplicar los métodos disponibles en Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88646105b4726c8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Se realiza la lectura del dataset sonar utilizando pandas\n",
    "    # La primera línea contiene los nombres de las variables\n",
    "    # header=None se utilizaría en caso de que no existiera una primera línea con los nombres para las variables\n",
    "\n",
    "# datos = <RELLENAR>\n",
    "\n",
    "# Generamos los datos de entrada y de salida: nos quedamos con las columnas correspondientes y la transformamos a un array de numpy\n",
    "X = np.array(datos.iloc[:,:-1].copy())\n",
    "# Transformamos la variable de las clases (valores discretos: strings) en valores numéricos de acuerdo a una codificación ordinal\n",
    "# y = <RELLENAR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-83576addd189d4f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Obtención del rendimiento con todas las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f1407b382ba2f52",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para comprobar la calidad del análisis de correlaciones (la influencia de eliminar variables correlacionadas), en primer lugar vamos a calcular el rendimiento del clasificador KNN (con la configuración por defecto) si utilizamos todas las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71250828e9784e62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En primer lugar vamos a obtener los conjuntos de entrenamiento y de test (70% de datos para entrenar). \n",
    "\n",
    "Se debe determinar la semilla para garantizar la reproducibilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2516f7058f1a47c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Se importan la librería necesarias\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Lllamada a la función train_test_split y guardado del resultado\n",
    "    # X_train e y_train contienen los ejemplo de entrenamiento\n",
    "    # X_test e y_test contienen los ejemplo de test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3d3d9d8c6d53848",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Obtener el accuracy rate tanto para el conjunto de entrenamiento (X_train) como para el conjunto de test (X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dced351dbbd445e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importan las 2 librerías necesarias para resolver el ejercicio\n",
    "from sklearn import neighbors, metrics\n",
    "\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "# knn =  <RELLENAR>\n",
    "# Llamada a la función que realiza el aprendizaje del clasificador\n",
    "# knn =  <RELLENAR>\n",
    "# Llamada a la función que realiza la predicción de los datos de entrenamiento\n",
    "# prediccionTrain =  <RELLENAR>\n",
    "# Llamada a la función que calcula el porcentaje de acierto para los datos de entrenamiento\n",
    "# accTrain =  <RELLENAR>\n",
    "print('El rendimiento en entrenamiento con todas las variables es el {}%'.format(accTrain))\n",
    "# Llamada a la función que realiza la predicción de los datos de test\n",
    "# prediccionTest =  <RELLENAR>\n",
    "# Llamada a la función que calcula el porcentaje de acierto para los datos de test\n",
    "# accTest =  <RELLENAR>\n",
    "print('El rendimiento en test con todas las variables es el {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-99963b51faf576fd",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(accTrain, 2), 86.21)\n",
    "assert_equal(round(accTest, 2), 68.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef93a0ca732596d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Análisis de correlaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8353d9eefd174313",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Visualización de la matriz de correlaciones\n",
    "\n",
    "En este apartado vamos a calcular y mostrar visualmente la matriz de correlaciones entre todas las variables de entrada junto con la variable a predecir. Para ello vamos a utilizar la librería Pandas y, en concreto, la función **corr** cuya información se puede encontrar en la URL: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ebee33deae9188cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Generamos el DataFrame a partir de los datos de entrada (X_train) y de salida (y_train)\n",
    "datosC = pd.DataFrame(data=np.hstack((X_train, y_train.reshape(-1,1))))\n",
    "\n",
    "# Calculamos la matriz de correlaciones con la función corr de pandas\n",
    "# correlaciones = <RELLENAR>\n",
    "\n",
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlaciones, vmin=-1, vmax=1, cmap=plt.cm.rainbow)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,61,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "# Si quisiéramos mostrar los nombres de las variables en la figura\n",
    "# names = list(datos.columns)\n",
    "# ax.set_xticklabels(names)\n",
    "# ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c3d07fb2ea88b69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "En este caso no se observa muy bien (puesto que la matriz es muy grande) que la matriz es simétrica (matriz triangular superior e inferior iguales). Además, se observa que la correlación entre una variable y ella misma es perfecta (diagonal con unos).\n",
    "\n",
    "Como la matriz es muy grande, para facilitar la visualización podemos hacer una gráfica con la última columna ya que indica la correlación de cada variable con la variable a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e34f43fc7dfb3ed5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# nos quedamos con la última columna del DataFrame correlaciones\n",
    "    # (todas las filas de correlaciones menos la última porque es la correlación de la variable a predecir consigo misma)\n",
    "# correlacionConClase = <RELLENAR>\n",
    "# Mostramos la correlación mínima y máxima\n",
    "print(correlacionConClase.min(), correlacionConClase.max())\n",
    "\n",
    "# Creamos el rango de las variables para mostrar su \"nombre\"\n",
    "rango = np.arange(0,60,1)\n",
    "\n",
    "# Creamos la figura\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(rango, correlacionConClase)\n",
    "plt.xticks(rango)\n",
    "plt.ylim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-85075738c8edf9ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "En este caso podemos observar que no hay ninguna variable de entrada que esté altamente correlacionada con la variable a predecir.\n",
    "\n",
    "Vamos a tratar de hacer las correlaciones entre las variables de entrada para descartar aquellas que estén altamente correlacionadas entre ellas y que, por tanto, no aporten información extra. Para obtener las variables correlacionadas vamos seleccionar las que tenga un valor de correlación mayor que un umbral (inicialmente lo asignamos a 0.8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7fb5b0a1e0f45c3b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Generamos un DataFrame con los datos de entrada (X_train)\n",
    "# datos = <RELLENAR>\n",
    "# Mostramos las dimensiones del problema\n",
    "print(datos.shape)\n",
    "\n",
    "# Creamos la matriz de correlación en valor absoluto: función abs (da igual se se correlacionan positiva o negativamente)\n",
    "# corr_matrix = <RELLENAR>\n",
    "# Seleccionamos el triángulo superior de la matriz de correlación\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Umbral deseado para determinar variables correlacionadas\n",
    "umbral = 0.8\n",
    "# Obtenemos los índices de aquellas variables con correlación mayor al umbral deseado\n",
    "variables_a_eliminar = [column for column in upper.columns if any(upper[column] > umbral)]\n",
    "\n",
    "# Eliminamos las variables con alta correlación con algunda de las variables de entrada para los datos de entrenamiento\n",
    "datos = datos.drop(datos.columns[variables_a_eliminar], axis=1)\n",
    "# Mostramos las dimensiones del problema tras reducir las variables redundantes\n",
    "print(datos.shape)\n",
    "\n",
    "# Eliminamos las variables con alta correlación con algunda de las variables de entrada para los datos de test\n",
    "# datosTest = <RELLENAR>\n",
    "# datosTest = <RELLENAR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8d996cfb59326980",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(datos.shape[1], 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c98a74670d8766ff",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finalmente obtenemos el rendimiento de KNN con las variables seleccionadas. Recordad que con todas las variables el rendimiento en train es del 86.21% y en test del 68.25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e3a38235453ed039",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "# knn = <RELLENAR>\n",
    "# Llamada a la función que realiza el aprendizaje del clasificador con los datos tras eliminar las correlacionadas\n",
    "# knn = <RELLENAR>\n",
    "# Llamada a la función que realiza la predicción de los datos de entrenamiento (tras eliminar las correlacionadas)\n",
    "# prediccionTrain = <RELLENAR>\n",
    "# Llamada a la función que calcula el porcentaje de acierto para los datos de entrenamiento \n",
    "# accTrain = <RELLENAR>\n",
    "print('El rendimiento en entrenamiento con las variables no redundantes es el {}%'.format(accTrain))\n",
    "# Llamada a la función que realiza la predicción de los datos de test (tras eliminar las correlacionadas)\n",
    "# # prediccionTest = <RELLENAR>\n",
    "# Llamada a la función que calcula el porcentaje de acierto para los datos de test\n",
    "# accTest = <RELLENAR>\n",
    "print('El rendimiento en test con las variables no redundantes  es el {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b42bc0838d5c718c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(accTrain, 2), 85.52)\n",
    "assert_equal(round(accTest, 2), 71.43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc062597b19d0085",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Podéis cambiar el umbral para seleccionar las variables correlacionadas (de las que nos quedamos una) y ver cómo cambian los resultados. Evidentemente, si se cambia el umbral las celdas de autocorrección fallarán. Dejad el umbral 0.8 en caso de que haya que entregar el Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d18a179f61de3fd5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### PCA: Principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eba4f15f1787de57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Una técnica muy habitual a la hora de realizar reducción de datos por medio de transformaciones de variables es el análisis de las componentes principales (PCA, de sus siglas en inglés). Scikit-learn nos ofrece dicha técnica implementada en la clase *PCA* de la librería *decomposition*. Toda la información de dicha clase se puede encontrar en el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html. El constructor con los parámetros que vamos a utilizar en esta prñáctica es el siguiente:\n",
    "    \n",
    "    sklearn.decomposition.PCA(n_components: numCom, svd_solver='full')\n",
    "    \n",
    "El parámetro n_components puede tener diferentes valores al utilizar *svd_solver='full'*:\n",
    "* Si *numCom* es un valor entero especifica el númerto de componentes principales a mantener.\n",
    "* Si *numCom* es un valor real entre 0 y 1 especifica el porcentaje de la varianza que representan los  componentes principales seleccionados. \n",
    "\n",
    "El porcentaje de varianza que representa cada componente principal se puede encontrar en el atributo *explained_variance_ratio_* de la clase PCA. El número de componentes principales seleccionados se puede obtener en el atributo *n_components_* de la clase PCA.\n",
    "\n",
    "Al igual que el resto de técnicas de preprocesamiento, para ejecutar PCA se debe llamar al constructor de la clase PCA, luego entrenarlo, método *fit*, con los ejemplos de entrenamiento y finalmente el objeto entrenado se puede utilizar para transformar ejemplos a la nueva base mediante el método *transform*.\n",
    "\n",
    "En la siguiente celda debéis ejecutar PCA utilizando tantos componentes principales como sean necesarios para mantener el 95% de la varianza. Debéis entrenar PCA con los datos de entrenamiento obtenidos al comienzo de la práctica y transformar tanto los datos de entrenamiento como los de test. Dichos datos transformados serán utilizados para obtener el rendimiento de KNN tanto en entrenamiento como en test con su configuración por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e200163e735f81dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Creamos y entrenamos el objeto de la clase PCA apropiado para realizar el ejercicio\n",
    "# pca = <RELLENAR>\n",
    "\n",
    "# Transformamos los datos de entrenamiento y de test\n",
    "# X_train_pca = <RELLENAR>\n",
    "# X_test_pca = <RELLENAR>\n",
    "\n",
    "# Obtenemos el rendimiento de los datos transformados por PCA con el algoritmo KNN\n",
    "# accTrain = <RELLENAR>\n",
    "# accTest = <RELLENAR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-efbbb19abcfbde07",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(round(accTrain, 2), 86.90)\n",
    "assert_equal(round(accTest, 2), 71.43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f9a6d3b7b1e41b9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Algo interesante de PCA es que podemos analizar la influencia del número de componentes principales utilizados. Scikit-learn nos devuelve los componentes principales ordenados por importancia (varianza de información que representan). Por este motivo, el primer componente principal será el más importante, luego el segundo, etc...\n",
    "\n",
    "El objetivo de este ejercicio es que analicéis la influencia de los componentes principales. Para ello se debe crear un script que analice el rendimiento de KNN con los datos transformados por PCA al seleccionar desde un único componente principal hasta tantos como variables originales tenga el problema. Algo muy útil para analizar dicho rendimiento es crear una gráfica que muestre para cada posibiliad su porcentaje de información representada, su rendimietno en train y su rendimiento en test.\n",
    "\n",
    "En la siguiente celda se debe crear el código necesario para crear dicha gráfica y poder analizar el comportamiento de PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b524d299aa49aa1b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "listaAccTrain = [] # lista para almancenar el rendimiento de las diferentes posibilidades en train\n",
    "listaAccTest = [] # lista para almancenar el rendimiento de las diferentes posibilidades en test\n",
    "listaPorInf = [] # lista para almancenar el porcentje de información representado por las diferentes posibilidades\n",
    "for numPCs in range(X_train.shape[1]):\n",
    "    # Cread y entrenad el objeto de PCA con el número de componentes apropiado (más 1 por empezar el bucle en 0)\n",
    "    # Posteriormente, transformad los datos de entrenamiento y de test\n",
    "#     pca = <RELLENAR>\n",
    "#     X_train_pca = <RELLENAR>\n",
    "#     X_test_pca = <RELLENAR>\n",
    "    # Añadimos a la lista el porcentaje de varianza explicada por los componentes utilizados en la iteración\n",
    "    listaPorInf.append(pca.explained_variance_ratio_.sum()*100.0)\n",
    "\n",
    "    # Obtener el rendimiento de KNN con la configuración por defecto tanto en train como en test con los datos transformados\n",
    "        # Aádir dichos rendimientos a las listas correspondientes\n",
    "    # <RELLENAR>\n",
    "# Mostramos en negro la varianza explicada, en rojo el rendimiento en train y en verde el rendimiento en test\n",
    "plt.figure()\n",
    "plt.plot(range(X_train.shape[1]), np.array(listaPorInf), 'k')\n",
    "plt.plot(range(X_train.shape[1]), np.array(listaAccTrain), 'r')\n",
    "plt.plot(range(X_train.shape[1]), np.array(listaAccTest), 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0273e3d82a550461",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "# assert_equal(list(map(lambda x: round(x, 2), np.array(listaPorInf)[::4])), [34.92, 75.49, 87.89, 93.08, 96.17, 97.78, 98.7, 99.22, 99.54, 99.75, 99.89, 99.96, 99.99, 100.0, 100.0])\n",
    "assert_equal(list(map(lambda x: round(x, 2), np.array(listaAccTrain)[::4])), [75.17, 86.9, 87.59, 89.66, 86.21, 86.9, 85.52, 85.52, 86.21, 86.21, 86.21, 86.21, 86.21, 86.21, 86.21])\n",
    "assert_equal(list(map(lambda x: round(x, 2), np.array(listaAccTest)[::4])), [42.86, 68.25, 66.67, 69.84, 74.6, 68.25, 68.25, 68.25, 68.25, 68.25, 68.25, 68.25, 68.25, 68.25, 68.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04db2ceaca3d5eb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Del mismo modo que en el caso anterior se puede estudiar la influencia del porcentaje de información total (varianza) a representar por los componentes principales utilizados. Cread el código necesario para obtener el número de compomentes principales utilizados por los porcentajes de información 0.8, 0.85, 0.9 y 0.95 así como sus rendimientos en train y test. En este caso no hace falta realizar una gráfica pero debéis almacenar el número de componentes principales necesarios para alcanzar cada valor (variable *n_components_* del objeto de la clase PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8cd6bfc5cc5e3b46",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "listaAccTrain = [] # lista para almancenar el rendimiento de las diferentes posibilidades en train\n",
    "listaAccTest = [] # lista para almancenar el rendimiento de las diferentes posibilidades en test\n",
    "listaNumPCs = [] # lista para almancenar el número de compomentes principales de cada opción\n",
    "# <RELLENAR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e1bcb805a2cf691e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "# assert_equal(list(map(lambda x: x, listaNumPCs)), [7, 8, 11, 16])\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTrain)), [91.03, 88.28, 86.9, 86.9])\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [69.84, 69.84, 68.25, 71.43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c47992a755170a63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finalmente, algo muy interesante es analizar qué variables influyen más en cada componente principal. Para ello, lo que se suele realizar es calcular la correlación entre las nuevas variables creadas por PCA (los valores de los ejemplos tras realizar la transformación) y las variables originales. Por ejemplo, para analizar las variables que más influyen al primer componente principal (PC1) deberemos realizar la correlación entre los valores de todos los ejemplos tras realizar la transformación con el PC1 y los valores de todos los ejemplos con cada variable original. De este modo, si una variable tiene correlación positiva el valor del PC1 crecerá conforme crezca dicha variable y decrecerá en caso de correlación negativa. Este hecho se puede mostrar muy fácilmente relizando una gráfica con el comando *plot*.\n",
    "\n",
    "Para realizar la correlación entre las variables se puede utilizar la función *corrcoef* de Numpy: https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html. En este caso, la matiz de entrada tiene tantas filas como variables a calcular su correlación y tantas columnas como ejemplos.\n",
    "\n",
    "En la siguiente celda vamos a analizar la influencia de las variables originales en los componentes principales obtenidos al mantener el 95% de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5b1880245fa525f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Obtener los componentes principales de PCA (95% varianza) utiliando X_train para entrenar el modelo y transformar los datos\n",
    "# pca = <RELLENAR>\n",
    "# X_train_pca = <RELLENAR>\n",
    "\n",
    "# Concatenar verticalmente las matrices de ejemplos originales y transformados en ese orden (transpuestas para que las variables sean las filas)\n",
    "variablesConPCs = np.vstack((X_train.T,X_train_pca.T))\n",
    "# Obtener la matriz de correlaciones de la matriz anterior\n",
    "# correlacionesPCs = <RELLENAR>\n",
    "# Seleccionar las últimss n_components_ filas y las X_train.shape[1] primeras columnas de la matriz correlacionesPCs\n",
    "# corrPCsVars = <RELLENAR>\n",
    "\n",
    "# Figura que muestra la influencia de las variables originales en cada componente principal\n",
    "fig = plt.figure(1, figsize=(24,70))\n",
    "for i in range(corrPCsVars.shape[0]):\n",
    "    fig.add_subplot(corrPCsVars.shape[0],1,i+1)\n",
    "    plt.title(\"PC\"+str(i+1))\n",
    "    plt.ylim([-1,1])\n",
    "    plt.bar(range(corrPCsVars.shape[1]),corrPCsVars[i,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-24d2f038114bc1ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-297afdafdcde0971",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para finalizar la práctica vamos utilizar una clase que nos permite realizar una secuencia de transformaciones a los datos (pre-procesamiento) que finalmente se aplicarán para entrenar un clasificador. Es decir, podemos crear una composición de varias fases de pre-procesamiento (todas las que queramos) junto con el aprendizaje de un clasificador sin tener que realizarlas independientemente.\n",
    "\n",
    "La clase que nos ofrece esta posibilidad está dentro de la librería Pipeline y la clase tiene el mismo nombre, Pipeline. Toda la información de esta clase la podéis encontrar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\n",
    "\n",
    "La llamada al constructor de esta clase consiste en un conjunto de tuplas del tipo (nombreFase, objeto), cuyo significado es:\n",
    "* nombreFase: string que establece el nombre de la fase. Por ejemplo 'PCA' o 'clasificadorKNN'\n",
    "* objeto: variable en la que se almacena la llamada al constructor de lo que se desee hacer. Por ejemplo PCA(n_components=0.95, svd_solver='full') o neighbors.KNeighborsClassifier()\n",
    "\n",
    "Es decir, si deseáramos combinar ambos procesos deberíamos realizar la siguiente llamada:\n",
    "\n",
    "    combinado = Pipeline([('PCA', PCA(n_components=0.95, svd_solver='full'), ('clasificadorKNN', neighbors.KNeighborsClassifier())])\n",
    "    \n",
    "Hay que destacar que los objetos de todas las fases (excepto de la última) tienen que tener los métodos fit y transform, para que puedan aprender de los datos y transformarlos en consecuencia. El último objeto debe tener el método fit, para aprender de los datos, y el método predict para poder realizar nuevas predicciones. Es decir, el último objeto debe ser un modelo de clasificación o regresión.\n",
    "\n",
    "El objeto combinado, la Pipeline generada, dispone de los siguientes métodos:\n",
    "* fit: Recibe como parámetros de entrada los datos de entrada (X) y de salida (Y). Cada objeto de cada fase aprende en base a dichos datos.\n",
    "* predict: Recibe como parámetro de entrada los datos de entrada (X). Realiza la predicción realizando lo siguiente:\n",
    "    * Primero se aplican las transformaciones de datos por medio de los primeros objetos (llaman a sus respectivas funciones transform)\n",
    "    * Finalmente, se aplica al objeto de la última fase (clasificador o modelo de regresión) para realizar la predicción correspondiente a los datos de entrada (llamada a su método predict). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6968476e533a4f16",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Realizar una Pipeline que combine:\n",
    "* PCA para representar el 95% de la varianza\n",
    "    * PCA(n_components=0.95, svd_solver='full')\n",
    "* Clasificador KNN\n",
    "    * neighbors.KNeighborsClassifier()\n",
    "\n",
    "Para ello, utiliza los conjuntos de entrenamiento y test generados al comienzo de la práctica.\n",
    "\n",
    "Comprueba que los resultados son los mismos que los obtenidos cuando hemos utilizado por separado ambos objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9065e0b2ec3a4250",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la librería pipeline\n",
    "from sklearn import pipeline\n",
    "\n",
    "# Se crea la Pipeline con las fases deseadas\n",
    "# combo = <RELLENAR>   \n",
    "# Se realiza el aprendizaje de los parámetros de todas las fases de la Pipeline\n",
    "# combo = <RELLENAR>\n",
    "# Se llama a la predicción de la pipeline sobre los datos de entrenamiento\n",
    "# prediccionesTrain = <RELLENAR>\n",
    "# Se calcula el accuracy para los datos de entrenamiento (entre 0.0 y 100.0)\n",
    "# accTrain = <RELLENAR>\n",
    "print('Resultado en entrenamiento: {}%'.format(accTrain))\n",
    "# Se llama a la predicción de la pipeline sobre los datos de test\n",
    "# prediccionesTest = <RELLENAR>\n",
    "# Se calcula el accuracy para los datos de test (entre 0.0 y 100.0)\n",
    "# accTest = <RELLENAR>\n",
    "print('Resultado en test: {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c172b129563c6dc0",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(accTrain, 2), 86.90)\n",
    "assert_equal(round(accTest, 2), 71.43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5af6760dc0cc36a3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Realizar una Pipeline que combine el filtro ANOVA anterior, el clasificador KNN y además realice en primer lugar la normalización de datos utilizando el método de los mínimos y los máximos:\n",
    "    * preprocessing.MinMaxScaler()\n",
    "\n",
    "NOTA: recodar que hay que importar la librería preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a6006241e629dda",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la librería de pre-procesamiento para hacer la normalización\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Se crea la Pipeline con las fases deseadas\n",
    "# combo = <RELLENAR>\n",
    "# Se realiza el aprendizaje de los parámetros de todas las fases de la Pipeline\n",
    "# combo = <RELLENAR>\n",
    "# Se llama a la predicción de la pipeline sobre los datos de entrenamiento\n",
    "# prediccionesTrain = <RELLENAR>\n",
    "# Se calcula el accuracy para los datos de entrenamiento (entre 0.0 y 100.0)\n",
    "# accTrain = <RELLENAR>\n",
    "print('Resultado en entrenamiento: {}%'.format(accTrain))\n",
    "# Se llama a la predicción de la pipeline sobre los datos de test\n",
    "# prediccionesTest = <RELLENAR>\n",
    "# Se calcula el accuracy para los datos de test (entre 0.0 y 100.0)\n",
    "# accTest = <RELLENAR>\n",
    "print('Resultado en test: {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cd81f199bfd692c8",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(accTrain, 2), 91.72)\n",
    "assert_equal(round(accTest, 2), 76.19)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

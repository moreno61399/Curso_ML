{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03fe3b9cd2623d3ebee18e3f4eafa0c5",
     "grade": false,
     "grade_id": "cell-a7f1dee03483c56a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Práctica de validación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1fb489af4b423f70b33b4d29b041a1c0",
     "grade": false,
     "grade_id": "cell-c1d42050f5d06517",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "- [Método Hold-out](#Método-Hold-out)\n",
    "- [Método validación cruzada de k particiones](#Método-validación-cruzada-de-k-particiones)\n",
    "- [Método Leave-One-Out](#Método-Leave-One-Out)\n",
    "- [Selección de modelos](#Selección-de-modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6afe50b1d8308592b2c7d80c54bdb101",
     "grade": false,
     "grade_id": "cell-e30c1d2b0de9e5bc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Importamos todas las librerías que vamos a utilizar durante la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d626eac94ca3c1cc3a50ac452f51405b",
     "grade": false,
     "grade_id": "cell-703d361146ac2cb3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "34d99a5384757dd6cfa68f6d4ca8a52d",
     "grade": false,
     "grade_id": "cell-8ab970703e2e4e41",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La librería scikit-learn nos ofrece muchas funcionalidades para realizar procesos de aprendizaje automático. En esta práctica vamos a utilizar las funciones que realizan métodos de validación de modelos. Todas estas funciones están dentro de la librería cross_validation. Para ello utilizaremos algunos de los clasificadores vistos en clase y finalmente, realizaremos la selección de los valores más adecuados (de entre un conjunto de valores) para los parámetros de cada clasificador para resolver un problema dado.\n",
    "\n",
    "En concreto, para desarrollar la práctica vamos a trabajar con el dataset Ionosphere. Este dataset contiene la información de un problema en el que un sistema de radar recoge información de 16 antenas con el objetivo de ver si los electrones presentan algún tipo de estructura en la ionosfera (Bueno) o no (Malo). Toda la información de este dataset se puede encontrar en la URL: https://archive.ics.uci.edu/ml/datasets/Ionosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79577b97beb060be853e6a95dbbd4e14",
     "grade": false,
     "grade_id": "cell-ab6645525903a51f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "En el siguiente código se deben leer los datos del problema Ionosphere almacenados en un archivo ionosphere.csv. En este caso la variable de salida (la última, llamada Class) está codificada con strings puesto que es una variable discreta y, por lo tanto, debéis convertirla a valores numéricos (utilizando una codificación ordinal) para poder aplicar los métodos disponibles en Scikit-learn.\n",
    "\n",
    "Realiza la lectura de los datos almacenados en el fichero ionosphere.dat y guardar el resultado en una variable llamada ion. A partir de la variable ion, generad las variables X (información de entrada) e y (información de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0d737757db25459599ac0cddf68a373d",
     "grade": false,
     "grade_id": "cell-9351b4b3d3b92c3a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se realiza la lectura del dataset sonar utilizando pandas\n",
    "    # La primera línea contiene los nombres de las variables\n",
    "    # header=None se utilizaría en caso de que no existiera una primera línea con los nombres para las variables\n",
    "\n",
    "# ion = <RELLENAR>\n",
    "\n",
    "# Generamos los datos de entrada y de salida: nos quedamos con las columnas correspondientes y la transformamos a un array de numpy\n",
    "# X = <RELLENAR>\n",
    "# Transformamos la variable de las clases (valores discretos: strings) en valores numéricos de acuerdo a una codificación ordinal\n",
    "# y = <RELLENAR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c48591908711ccb7f6575dbe92338c9e",
     "grade": false,
     "grade_id": "cell-347ed2cbf584062c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Método Hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "74255144a24dae060c4ab5b682a521ae",
     "grade": false,
     "grade_id": "cell-33423ca7e5cd88b3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "El método de validación hold-out crea un conjunto de ejemplos de entrenamiento y uno de test a partir del conjunto de datos inicial. Para ello, se determina el porcentaje de ejemplos a utilizar como conjunto de entrenamiento. Estos ejemplos serán escogidos aleatoriamente. El resto de ejemplos (no asignados al conjunto de entrenamiento) serán asignados al conjuntos de test.\n",
    "\n",
    "Como hemos dicho anteriormente, en la librería model_selection de scikit-learn podemos encontrar una función que realiza este proceso. Por tanto, en primer lugar, para poder utilizarla se debe importar dicha librería de este modo\n",
    "\n",
    "    from sklearn import model_selection\n",
    "\n",
    "Dentro de esta librería se encuentra la función llamada train_test_split que nos realiza el proceso de división de los datos aplicando la técnica Hold-out. Toda la información de esta función la podéis consultar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split\n",
    "\n",
    "La función recibe varios parámetros de entrada y devuelve varios parámetros de salida, la llamada a dicha función es la siguiente:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(inputData, outputData, train_size=porcentajeTrain)\n",
    "\n",
    "* Los parámetros de entrada son:\n",
    "    * inputData: los datos de entrada, el campo data del objeto dataset\n",
    "    * outputData: los datos de salida, el campo target del objeto dataset\n",
    "    * porcentajeTrain: la proporción de ejemplos de entrenamiento\n",
    "* Los parámetros de salida son:\n",
    "    * X_train: los datos de entrada del conjunto de entrenamiento\n",
    "    * X_test: los datos de entrada del conjunto de test\n",
    "    * y_train: los datos de salida del conjunto de entrenamiento\n",
    "    * y_test: los datos de salida del conjunto de test\n",
    "    \n",
    "NOTA: Los ejemplos asignados a cada partición se escogen al azar por lo que de ejecución a ejecución los resultados pueden variar. Para evitar este comportamiento podemos determinar la semilla a utilizar a la hora de generar los números aleatorios. La semilla será un número entero que implica que el número aleatorio generado es siempre el mismo. Por tanto, los ejemplos irán siempre a la misma partición y los resultados serán siempre los mismo. Para fijar la semilla de Numpy, que es la utilizada, se utiliza la siguiente instrucción:\n",
    "\n",
    "    np.random.seed(valorEntero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3d798a14edd043d0988b667cd6094354",
     "grade": false,
     "grade_id": "cell-7a76aeb1cdef1d47",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ejercicio: utilizar el método de validación hold-out para obtener el accuracy de entrenamiento y de test con el dataset Ionosphere y utilizando el árbol de decisión C4.5 con la configuración por defecto vista en la práctica anterior. Utilizar como semilla el número 12. \n",
    "\n",
    "Comprobar cómo cambian los resultados al variar el porcentaje de ejemplos de entrenamiento (50%, 60%, 70% y 80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b4457319bb1cf87470cdad5b55cabd85",
     "grade": false,
     "grade_id": "cell-e07ea8292d4145bc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importan las 3 librerías necesarias para resolver el ejercicio\n",
    "from sklearn import tree, metrics, model_selection\n",
    "\n",
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Listas para almacenar los resultados de accuracy en train y test\n",
    "listaAccTrain = []\n",
    "listaAccTest = []\n",
    "# Para cada porcentaje de ejemplos a utilizar como entrenamiento\n",
    "for porcentajeEjemplosTrain in [0.5,0.6,0.7,0.8]:\n",
    "    # Lllamada a la función train_test_split y guardado del resultado\n",
    "#     <RELLENAR>\n",
    "    # Llamada al constructor del árbol de decisión con el parámetro necesario para que sea el C4.5\n",
    "#     arbolDecision = <RELLENAR>\n",
    "    # Entrenamiento del árbol de decisión C4.5\n",
    "#     arbolDecision = <RELLENAR>\n",
    "    # Predicción de los datos de entrenamiento\n",
    "#     predictionTrain = <RELLENAR>\n",
    "    # Cálculo del porcentaje de acierto en entrenamiento (entre 0.0 y 100.0)\n",
    "#     accTrain = <RELLENAR>\n",
    "    print('Utilizando el {}% de los ejemplos como train se obtiene un accuracy del {}% en entrenamiento'.format(porcentajeEjemplosTrain, accTrain))\n",
    "    # Se almacena el resultado en entrenamiento para este porcentaje de ejemplos a utilizar como entrenamiento\n",
    "    listaAccTrain.append(accTrain)\n",
    "    # Predicción de los datos de test\n",
    "#     predictionTest = <RELLENAR>\n",
    "    # Cálculo del porcentaje de acierto en test (entre 0.0 y 100.0)\n",
    "#     accTest = <RELLENAR>\n",
    "    print('Utilizando el {}% de los ejemplos como train se obtiene un accuracy del {}% en test'.format(porcentajeEjemplosTrain, accTest))\n",
    "    # Se almacena el resultado en test para este porcentaje de ejemplos a utilizar como entrenamiento\n",
    "    listaAccTest.append(accTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b042cbe1e599a42e53304f56cd274be0",
     "grade": true,
     "grade_id": "cell-5faf15388edd6202",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaAccTest)), [86.93, 90.78, 92.45, 80.28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36fdd818d0e9228b5e78a628b79cf6cb",
     "grade": false,
     "grade_id": "cell-e8975a50c2107c27",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Método validación cruzada de k particiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19e21811b5f2d024b2a9884d2cec9a12",
     "grade": false,
     "grade_id": "cell-c945541297535884",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "El método de validación cruzada de k particiones, divide el conjunto de ejemplos original en k particiones manteniendo la distribución de las clases. Posteriormente, para realizar el aprendizaje se fusionan 4 de estas particiones para formar el conjunto de entrenamiento y la partición restante se utiliza como conjunto de test. Este proceso se realiza k veces utilizando una partición diferente como conjunto de test cada vez. En scikit-learn, existe una función llamada StratifiedKFold (también en la librería model_selection) que realiza la división del conjunto de ejemplos original en particiones y forma los k conjuntos de entrenamiento y de test. La información de esta función la podéis encontrar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "La llamada al constuctor y sus principales parámetros de entrada son:\n",
    "\n",
    "    validacionCruzada = model_selection.StratifiedKFold(n_splits=numeroParticiones, random_state=semilla)\n",
    "\n",
    "Los parámetros de entrada son:\n",
    "* numeroParticiones: valor entero que determina el número de particiones a generar. Por defecto es 3.\n",
    "* semilla: valor que determina la semilla para la generación de números aleatorios.\n",
    "\n",
    "Para generar los iteradores de índices se debe ejecutar el método split utilizando el objeto generado por el constructor (variable validacionCruzada). Al método split se le deben pasar tanto los datos se entrada como las clases (dos variables separadas por comas).\n",
    "\n",
    "    iteradorIndices = validacionCruzada.split(X, y)\n",
    "    \n",
    "Una vez realizada esta instrucción se puede realizar el bucle para realizar las k iteraciones:\n",
    "  \n",
    "    for train_index, test_index in iteradorIndices:\n",
    "\n",
    "De esta forma el bucle for se realizará K veces y en cada iteración tendremos:\n",
    "\n",
    "* En la variable train_index estarán los índices de los ejemplos a utilizar como conjunto de entrenamiento. El conjunto de entrenamiento estará formado por todas las filas del campo data cuyos índices estén en train_index y todas las columnas (para las clases lo mismo pero con el campo target). Es decir, datos.data[train_index, :] y datos.target[train_index].\n",
    "* En la variable test_index estarán los índices de los ejemplos a utilizar como conjunto de test. El conjunto de test estará formado por todas las filas del campo data cuyos índices estén en test_index y todas las columnas (para las clases lo mismo pero con el campo target). Es decir, datos.data[test_index, :] y datos.target[test_index]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9fd24999a735a74c83b903ff4bb54d58",
     "grade": false,
     "grade_id": "cell-bbd385dfa512e684",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ejercicio: realizar el proceso de validación cruzada para el dataset Ionosphere y mostrar para cada partición (iteración del bucle for) el accuracy en train y en test. Probar 5 y 10 como valores de K. Utilizar como clasificador el árbol de decisión C4.5 con la configuración por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bbd987d552cb8ffcd277bd01d4c0fd99",
     "grade": false,
     "grade_id": "cell-1f43b836ab9e3ae6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Listas para almacenar los resultados de accuracy en train y test\n",
    "listaMediasTrain = []\n",
    "listaMediasTest = []\n",
    "# Para las dos validaciones cruzadas (de 5 y de 10 particiones)\n",
    "for k in [5, 10]:\n",
    "    # Llamada al constructor de la validación cruzada\n",
    "#     skf = <RELLENAR>\n",
    "    # Llamada a la función que nos da los iteradores con los índices de los ejemplos a utilizar en entrenamiento y en test\n",
    "#     iteradorIndices = <RELLENAR>\n",
    "    # Se crear las variables para almacenar los k resultados de entrenamiento y de test\n",
    "    train = np.zeros(k)\n",
    "    test = np.zeros(k)\n",
    "    i = 0\n",
    "    # Bucle para realizar la validación cruzada\n",
    "    for train_index, test_index in iteradorIndices:\n",
    "        # Llamada al constructor del árbol de decisión con el parámetro necesario para que sea el C4.5\n",
    "#         arbolDecision = <RELLENAR>\n",
    "        # Entrenamiento del árbol de decisión con los ejemplos de entrenamiento\n",
    "            # Todas las filas correspondientes a los índices contenidos en train_index\n",
    "#         arbolDecision = <RELLENAR>\n",
    "        # Predicción de los ejemplos de entrenamiento\n",
    "#         predictionTrain = <RELLENAR>\n",
    "        # Cálculo del porcentaje de acierto en entrenamiento (entre 0.0 y 100.0)\n",
    "#         train[i] = <RELLENAR>\n",
    "        print('En la partición {} se obtiene un accuracy del {}% en entrenamiento'.format(i, train[i]))\n",
    "        # Predicción de los ejemplos de test\n",
    "            # Todas las filas correspondientes a los índices contenidos en test_index\n",
    "#         predictionTest = <RELLENAR>\n",
    "        # Cálculo del porcentaje de acierto en test (entre 0.0 y 100.0)\n",
    "#         test[i] = <RELLENAR>\n",
    "        print('En la partición {} se obtiene un accuracy del {}% en test'.format(i, test[i]))\n",
    "        i += 1\n",
    "    # Cálculo y guardado de las medias de las k particiones tanto de entrenamiento como de test\n",
    "    mediaTrain = np.mean(train)\n",
    "    print('La media de las {}% particiones en train es: {}%'.format(k, mediaTrain))\n",
    "    listaMediasTrain.append(mediaTrain)\n",
    "    mediaTest = np.mean(test)\n",
    "    print('La media de las {}% particiones en test es: {}%'.format(k, mediaTest))\n",
    "    listaMediasTest.append(mediaTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "315bd42881567826ffbc628829d9cb76",
     "grade": true,
     "grade_id": "cell-d8e5c1bd4e509d5c",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaMediasTrain)), [100.00,100.00])\n",
    "assert_equal(list(map(lambda x: round(x, 2), listaMediasTest)), [84.63,85.58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "07c404916bdb622e5372e2edba864e56",
     "grade": false,
     "grade_id": "cell-1c77391dcf3b0804",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Método Leave-One-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3ee523bd73636e70b5e7781287a814e",
     "grade": false,
     "grade_id": "cell-4056f3d1e1f5af43",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "El tercer método de validación es el leave-one-out. Es como el método de validación cruzada de k particiones cuando k es igual al número de ejemplos del dataset. La función de scikit-learn que realiza este proceso es LeaveOneOut y su información puede encontrarse en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut\n",
    "\n",
    "Su llamada y su uso es el siguiente:\n",
    "\n",
    "    loo = model_selection.LeaveOneOut()\n",
    "    \n",
    "Al igual que para la validación cruzada, para generar los iteradores de índices, se debe ejecutar el método split utilizando el objeto generado por el constructor (variable loo). En este caso, solamente es necesario pasar como parámetro de entrada los valores de entrada de los ejemplos (X).\n",
    "\n",
    "    iteradorIndices = loo.split(X)\n",
    "    \n",
    "Una vez realizada esta instrucción se puede realizar el bucle para realizar las k iteraciones del mismo modo que anteriormente. La diferencia es que en cada iteración, en la variable test_index solo habrá un índice puesto que se usa un solo ejemplo para evaluar el modelo aprendido. Por tanto, para obtener el resultado en test se debe almacenar, en cada iteración del bucle for, la predicción del ejemplo de test (en un vector de tantos elementos como ejemplos del dataset) y al finalizar el bucle for se debe comparar este vector con las clases reales del problema (campo target) para obtener el accuracy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec735d7c6b4ac1c438885f90767dd092",
     "grade": false,
     "grade_id": "cell-37733bea617a6ef4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ejercicio: realizar el método de validación leave-one-out con el dataset Ionosphere utilizando C4.5 con la configuración por defecto y mostrar el accuracy obtenido en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a8c4c3d4d19ebbcff4a67497570ad74e",
     "grade": false,
     "grade_id": "cell-c7302eeca982aa7e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Llamada al constructor del proceso leave one out\n",
    "# loo = <RELLENAR>\n",
    "# Llamada a la función que nos da los iteradores con los índices de los ejemplos a utilizar en entrenamiento y en test\n",
    "# iteradorIndices = <RELLENAR>\n",
    "# Se crea un array para almacenar la salida de la predicción de cada ejemplo\n",
    "test = np.zeros(X.shape[0])\n",
    "i = 0\n",
    "# Para cada partición de ejemplos\n",
    "for train_index, test_index in iteradorIndices:\n",
    "    # Llamada al constructor del árbol de decisión con el parámetro necesario para que sea el C4.5\n",
    "#     arbolDecision = <RELLENAR>\n",
    "    # Entrenamiento del árbol de decisión con los ejemplos de entrenamiento\n",
    "            # Todas las filas correspondientes a los índices contenidos en train_index\n",
    "#     arbolDecision = <RELLENAR>\n",
    "    # Predicción del ejemplo de test\n",
    "#     test[i] = <RELLENAR>\n",
    "    i += 1\n",
    "# Cálculo del accuracy de las predicciones realizadas en test (entre 0.0 y 100.0)\n",
    "# accTest = <RELLENAR>\n",
    "print('El accuracy en test es: {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ecac410eaa11b2097f9c35ed28944184",
     "grade": true,
     "grade_id": "cell-9d2a23e3f2ec6cf7",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(accTest, 2), 88.32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5dbfddab28f4ec4387ac50d2c5e1f671",
     "grade": false,
     "grade_id": "cell-192be9c1848a2266",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Selección de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73b11c0dfb4155413d8a647b65054ced",
     "grade": false,
     "grade_id": "cell-1294cab6f9bcaed5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "En prácticas anteriores hemos visto que los resultados de los clasificadores varían en función de los valores de sus parámetros. Para determinar los mejores valores (de entre un conjunto de valores posibles) para los parámetros vamos a utilizar el modelo de validación cruzada de 10 particiones. De esta forma, evaluaremos la calidad de cada configuración del clasificador (genera un modelo diferente) utilizando la validación cruzada y elegiremos la configuración con mejor rendimiento medio en test.\n",
    "\n",
    "Este procedimiento se realizaría para determinar la mejor configuración de cualquier clasificador para un problema dado. En esta práctica vamos a utilizarlo para resolver el problema de Inosphere y determinar la mejor configuración del clasificador KNN y de los árboles de decisión. \n",
    "\n",
    "Para ello vamos a utilizar una función de scikit-learn que nos ayuda a realizar dicho proceso. Esta función también está dentro del paquete **model_selection** y se llama GridSearchCV. Toda la información de esta función la podéis consultar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html. Su llamada y sus parámetros principales son los siguientes:\n",
    "\n",
    "    clasificadores = model_selection.GridSearchCV(clasificador, param_grid, scoring=tipoRendimiento, cv=numParticiones, return_train_score=devolverResultadosTrain)\n",
    "\n",
    "* clasificador: es el clasificador del que deseamos conocer su mejor configuración. Es decir, la variable en la que almacenamos la llamada en la que definimos el clasificador (sin parámetros de entrada).\n",
    "* param_grid: es un diccionario cuyas claves son los nombres de los parámetros a determinar su mejor configuración. Para cada clave su valor es una lista con los valores que se desean probar para dicho parámetro. Por ejemplo, para los dos clasificadores que vamos a \"optimizar\" podría ser:\n",
    "    * KNN: {'n_neighbors': [1, 3, 5, 7, 9], 'weights': [‘uniform’, ‘distance’], ‘p’: [1, 2, 1.5, 3]}\n",
    "    * Árboles de decisión:  {'criterion': [‘gini’, ‘entropy’], ‘min_samples_split': [2, 5, 10], ‘min_samples_leaf’: [1, 2, 4]}\n",
    "* tipoRendimiento: determina el tipo de medida a utilizar para evaluar la calidad del clasificador. Si no se especifica se utiliza la que aplica el clasificador a optimizar (normalmente todos utilizar el accuracy). Los posibles valores de este parámetro son:\n",
    "    * ’accuracy’: accuracy rate\n",
    "    * ‘precision’: precisión\n",
    "    * ‘recall’: recall o true positive rate\n",
    "    * ‘roc_auc’: área bajo la curva ROC\n",
    "* numParticiones: número de particiones a utilizar en el modelo de validación cruzada de k particiones. Por defecto su valor es 3.\n",
    "* devolverResultadosTrain: variable booleana que determina si se devuelven los resultados de entrenamiento o no. Por defecto su valor es False.\n",
    "\n",
    "El parámetro de salida es un conjunto de clasificadores (todas las posibles combinaciones de los parámetros a utilizar). Al igual que hacemos con un solo clasificador, debemos entrenar todos ellos con los datos de train (llamada a la función fit con la variable donde se almacena el conjunto de clasificadores). En este caso, la llamada al entrenamiento ya realiza internamente tanto el entrenamiento como la evaluación del rendimiento de los clasificadores. Por este motivo, tras entrenarlos (llamada a fit), ya se ha calculado internamente la mejor configuración. En concreto está almacenada en el campo best_params_ y su rendimiento asociado está almacenado en el campo best_score_. Podemos visualizarlos con print:\n",
    "\n",
    "    print clasificadores.best_params_\n",
    "    print clasificadores.best_score_\n",
    "\n",
    "Además, por defecto (refit es True) se entrena un clasificador con la mejor configuración encontrada que permite utilizar directamente el método predict sobre la instancia de *GridSearchCV* (usando dicho clasificador). Este clasificador también lo tenemos disponible mediante el atributo \n",
    "\n",
    "    clasificadores.best_estimator_\n",
    "    \n",
    "Para comprobar que efectivamente la configuración mostrada es la mejor, podemos visualizar los resultados de todos los clasificadores considerados (todas las combinaciones de hiper-parámetros posibles). PAra que el siguiente código funcione debéis especificar que se devuelvan los resultados de entrenamiento en el constructor. Para ello se debe utilizar el siguiente código:\n",
    "\n",
    "    resultadosMostrar = zip(clasificadores.cv_results_['params'],clasificadores.cv_results_['mean_test_score'],clasificadores.cv_results_['mean_train_score'])\n",
    "    for params, mean_test_score, mean_train_score in resultadosMostrar:\n",
    "        print(\"%0.3f (Train: %0.3f) for %r\" % (mean_test_score, mean_train_score, params))\n",
    "        print()\n",
    "\n",
    "Se puede observar que en la variable *resultadosMostrar* estamos utilizando el atributo *cv_results_* (es un DataFrame) y seleccionando algunas de sus columnas para mostrar (podríamos incluir más información)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c492ad55475a0e658240f747b20f1d4f",
     "grade": false,
     "grade_id": "cell-ce6ec077a2d2e42a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ejercicio: realizar el proceso de validación cruzada (utilizando 10 particiones, cv=10) para aprender los mejores valores del clasificador KNN y de los árboles de decisión (con los grids de parámetros mostrados en la celda anterior) para resolver este problema de clasificación uso. ¿Cuál es la mejor configuración de cada uno de ellos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fbb3cb9081ce06500b2a0032c698b27e",
     "grade": false,
     "grade_id": "cell-7c087aa03d97ff09",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se importan las librerías que vamos a utilizar en este ejercicio\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "# knn = <RELLENAR>\n",
    "# Se define el grid de parámetros a utilizar\n",
    "    # Estos parámetros nos darán todas las posibles configuraciones del clasificador KNN\n",
    "        # Cada combinación de parámetros es una configuración diferente\n",
    "# param_grid = <RELLENAR>\n",
    "\n",
    "# Llamada la función GridSearchCV que nos crea todas las cominaciones del grid anterior\n",
    "# clasificadores = <RELLENAR>\n",
    "# Entrenamiento de todos los clasificadores con todos los datos contenidos en ion (campos data y target)\n",
    "# clasificadores = <RELLENAR>\n",
    "# Se muestra la mejor confiugración y su accuracy asociado\n",
    "print(clasificadores.best_params_)\n",
    "print(clasificadores.best_score_)\n",
    "\n",
    "# Se muestra el accuracy obtenido para cada posible combinación de parámetros\n",
    "resultadosMostrar = zip(clasificadores.cv_results_['params'],clasificadores.cv_results_['mean_test_score'],clasificadores.cv_results_['mean_train_score'])\n",
    "for params, mean_test_score, mean_train_score in resultadosMostrar:\n",
    "    print(\"%0.3f (Train: %0.3f) for %r\" % (mean_test_score, mean_train_score, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6abbf9045bcf80cd142eb4c4daa8d968",
     "grade": true,
     "grade_id": "cell-176d098fa2a38ac9",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(clasificadores.best_score_, 4), 0.8860)\n",
    "assert_equal(clasificadores.best_params_, {'n_neighbors': 1, 'weights': 'uniform', 'p': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3f9ddfc190f9fcf07071c040dc5c4e59",
     "grade": false,
     "grade_id": "cell-a4951bc2ec37b1fc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "#Realizamos el proceso para los árboles de decisión por lo que hay que llamar al constructor de dicho clasificador\n",
    "# arbolDecision = <RELLENAR>\n",
    "# Cread el grid de parámetros\n",
    "# param_grid = <RELLENAR>\n",
    "\n",
    "# Llamada la función GridSearchCV que nos crea todas las combinaciones del grid anterior\n",
    "# clasificadores = <RELLENAR>\n",
    "# Entrenamiento de todos los clasificadores con todos los datos contenidos en ion (campos data y target)\n",
    "# clasificadores = <RELLENAR>\n",
    "# Se muestra la mejor configuración y su accuracy asociado\n",
    "print(clasificadores.best_params_)\n",
    "print(clasificadores.best_score_)\n",
    "\n",
    "# Se muestra el accuracy obtenido para cada posible combinación de parámetros\n",
    "resultadosMostrar = zip(clasificadores.cv_results_['params'],clasificadores.cv_results_['mean_test_score'],clasificadores.cv_results_['mean_train_score'])\n",
    "for params, mean_test_score, mean_train_score in resultadosMostrar:\n",
    "    print(\"%0.3f (Train: %0.3f) for %r\" % (mean_test_score, mean_train_score, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2ade5b9b18fe1399a1bcfe74fb8d96d",
     "grade": true,
     "grade_id": "cell-a8fec660986dedb4",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(clasificadores.best_score_, 4), 0.8746)\n",
    "assert_equal(clasificadores.best_params_, {'min_samples_split': 10, 'criterion': 'gini', 'min_samples_leaf': 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

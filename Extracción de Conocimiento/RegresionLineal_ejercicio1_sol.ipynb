{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01221df60961c67b2ca2b2d2c14036e4",
     "grade": false,
     "grade_id": "cell-63bf273c4aaddb90",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Ejercicio 1 - Regresión lineal\n",
    "\n",
    "- [Regresión lineal con una variable](#Regresión-lineal-con-una-variable)\n",
    "- [Descenso por gradiente](#Descenso-por-gradiente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98b6bffc6d049914a36f769bceeb1dfe",
     "grade": false,
     "grade_id": "cell-4352aa7538dc788e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "975632bad3be1437acd3b36198f7c90c",
     "grade": false,
     "grade_id": "cell-2efaf83e41c6d260",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Regresión lineal con una variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37668bfb17a2a0d7ee40a3f7e2c49a77",
     "grade": false,
     "grade_id": "cell-43d9ed99516f4941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En primer lugar se debe leer los datos almacenados en el fichero `ex1data.txt` mediante la **función loadtxt de NumPy**. Los datos contenidos en este fichero corresponden a un problema en el que se debe predecir el beneficio de un camión de comida (food truck) en base al número de habitantes de una ciudad. En este fichero está almacenado el histórico de los camiones de comida de una franquicia. La primera columna corresponde al número de habitantes de una ciudad (en decenas de miles) y la segunda columna corresponde a los beneficios obtenidos con el camión de comida (en decenas de miles).\n",
    "\n",
    "Mostrar los 5 primeros registros para comprobar que la lectura se haya realizado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "530124f75f31b53671dbf19575944444",
     "grade": false,
     "grade_id": "cell-870c2e63684d2752",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('ex1data1.txt', delimiter=',')\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89b5784d6b87266798adcefbd60a885b",
     "grade": false,
     "grade_id": "cell-5fd7c154e11b4abb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "A continuación debéis crear los datos de entrada (X) y de salida (y) para poder realizar el aprendizaje de los parámetros de la regresión lineal ($\\theta$). Recordar que la primera columna de los datos de entrada debe estar compuesta por unos para multiplicar al término independiente de la regresión lineal. Por tanto, la variable X estará compuesta por dos columnas: una de unos y otra con los datos correspondientes al número de habitantes de las ciudades. La variable y estará compuesta por los beneficios de los camiones de comida en las diferentes ciudades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d772a4393189c3eb5b16ee1151fa70b",
     "grade": false,
     "grade_id": "cell-4399eaac487c2c0f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# La función hstack de NumPy concatena dos arrays horizontalmente\n",
    "    # Debéis crear una columna de unos y concaternala con la primera columna de data\n",
    "    # Debéis cambiar las dimensiones de ambos arrays para que sean una columna (dimensiones (97L, 1L))\n",
    "# La función reshape de NumPy cambia las dimensiones de un array, para crear una sola columna se debe utilizar reshape(-1,1)\n",
    "    # El -1 calcula el número de filas adecuado para el número de columnas especificado (en este caso 1)\n",
    "\n",
    "# X = \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# y = \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "216d8a07ae8ff85511a7399e52c2ffeb",
     "grade": false,
     "grade_id": "cell-cdc217c94b823e59",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Vamos a mostrar una gráfica de puntos para visualizar la distribución de las instancias del problema. De esta forma podemos comprobar si es posible que el modelo de regresión lineal se ajuste bien a los datos o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e04496d9a7b8e1ce83a0ba1e9b42b02",
     "grade": false,
     "grade_id": "cell-27f7bf6a18c4c3b0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Numero de habitantes de las ciudades en decenas de miles.')\n",
    "plt.ylabel('Beneficio en decenas de miles de dolares.');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a19a872f4748af668eecdcf2c701e41b",
     "grade": false,
     "grade_id": "cell-da41ddc895f6917f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Descenso por gradiente\n",
    "\n",
    "A continuación se debe programar la función de coste para poder aplicar el algoritmo de aprendizaje y que los parámetros de la regresión lineal se ajusten a los datos de tal forma que se minimice dicho coste.\n",
    "\n",
    "Recordar que la función de coste es: $J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m \\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right)^2$\n",
    "\n",
    "La instrucción X.dot(theta) realiza el producto matricial de los datos de entrada por los parámetros de la regresión. Su resultado es la predicción del sistema para los datos de entrada: $h_{\\theta}\\left(x^{(i)}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2c413eee1e98c3ca381e6dad7e3f277",
     "grade": false,
     "grade_id": "cell-fb37a90b945f176b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    \n",
    "    h = X.dot(theta)\n",
    "    \n",
    "#     J = \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b47d5f368f40342e84f2df75bd2f824",
     "grade": false,
     "grade_id": "cell-b3094d9f1acc5a4e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Vamos a comprobar si la función de coste está bien hecha. Para ello debéis crear los valores iniciales de los parámetros de la regresión lineal como un array columna de ceros (lista de listas de un elemento). Luego, debéis llamar a la función computeCost con los datos de entrada (X), de salida (y) y los parámetros del modelo ($\\theta$). Almacenar el resultado en la variable resultado.\n",
    "\n",
    "Imprimir en pantalla el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49e57dacf608390c77ee3ca497b29ab9",
     "grade": false,
     "grade_id": "cell-e9d1853ce8d3f777",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# theta = #<RELLENAR>\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# resultado = #<RELLENAR>\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862e1a3184551a0ad8732161dec7bb55",
     "grade": true,
     "grade_id": "cell-112fd6c583614235",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(resultado, 5), 32.07273)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13222b07e370bd475ac09773393e0233",
     "grade": false,
     "grade_id": "cell-2cc10cb72c4b89ae",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "A continuación se muestra la implementación de la función que implementa el descenso por gradiente para realizar el aprendizaje de los parámetros del modelo. Esta función recibe como parámetros de entrada los valores de entrada, de salida, los valores iniciales del modelo, el valor que establece la velocidad de convergencia del algoritmo ($\\alpha$) y el número de iteraciones a realizar por el algoritmo.\n",
    "\n",
    "Como salida devuelve los parámetros aprendidos (variable theta) así como el historial de la evolución de error cometido con cada configuración de valores del modelo (variable J_history). Fijaros que esta última variable almacena el resultado de la función de coste implementada anteriormente para los valores del modelo que han sido actualizados en la instrucción anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc7523c5e9b2db95942a6afbd6e24de8",
     "grade": false,
     "grade_id": "cell-83f705e21bf92417",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha=0.01, num_iters=1500):\n",
    "    m = y.size\n",
    "    J_history = np.zeros(num_iters)\n",
    "    \n",
    "    for iter in np.arange(num_iters):\n",
    "        h = X.dot(theta)\n",
    "        theta = theta - alpha*(1.0/m)*(X.T.dot(h-y))\n",
    "        J_history[iter] = computeCost(X, y, theta)\n",
    "    return(theta, J_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar el aprendizaje. Para ello se debe llamar a la función gradientDescent con los valores de entrada (X), los de salida (y) y los valores iniciales de los parámetros del modelo ($\\theta$), inicializados a cero anteriormente.\n",
    "\n",
    "A continuación se muestran por pantalla y se comprueba si son correctos.\n",
    "\n",
    "Finalmente, se muestra la gráfica de la evolución del error con respecto a las iteraciones del descenso por gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5e04cdb12d3fd8d86ecefbc76e7947c",
     "grade": false,
     "grade_id": "cell-8fbd74952d022ef1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# theta para minimizar la función de coste J\n",
    "# theta , Cost_J = #<RELLENAR>\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print('theta: ',theta.ravel())\n",
    "\n",
    "plt.plot(Cost_J)\n",
    "plt.ylabel('Cost J')\n",
    "plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "433536fcc67e2f7308a31e90ca660375",
     "grade": true,
     "grade_id": "cell-4500b01f95d6e5f2",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(list(map(lambda ind: round(ind, 5), list(theta.ravel()))), [-3.63029,  1.16636])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fdfe15c18e4e53646e5e5d908153b92",
     "grade": false,
     "grade_id": "cell-250399643dcd983d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Ahora vamos a mostrar la recta aprendida. \n",
    "\n",
    "Para ello debéis crear una array de valores comprendidos entre 5 y 23 con incrementos de 1 en 1 y almacenarlo en la variable xx. \n",
    "\n",
    "A continuación evaluar todos estos valores utilizando los valores del modelo aprendidos anteriormente (variable theta) y almacenarlos en la variable yy. Se debe aplicar la ecuación de la recta: $y = n+m*x$.\n",
    "\n",
    "Por último se muestra la recta aprendida en la figura que también incluye los puntos a partir de los que se ha realizado el aprendizaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b29e6945a037c9753d2b93ad59f0578e",
     "grade": false,
     "grade_id": "cell-4ae41c92bd6eeab2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# xx = #<RELLENAR>\n",
    "# YY = #<RELLENAR>\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Mostramos el descenso por gradiente\n",
    "plt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\n",
    "plt.plot(xx,yy, label='Regresion lineal (Descenso por gradiente)')\n",
    "\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Numero de habitantes de las ciudades en decenas de miles.')\n",
    "plt.ylabel('Beneficio en decenas de miles de dolares.');\n",
    "plt.legend(loc=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "579b533ec97bd193211fa0682b850785",
     "grade": false,
     "grade_id": "cell-a84b24c3b93f2841",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Una vez realizado el proceso de aprendizaje con funciones definidas por nosotros vamos a pasar a usar la librería ofrecida por Python para realizar tareas de aprendizaje automático. Esta librería se llama scikit-learn y se puede visitar en la siguiente URL: http://scikit-learn.org/stable/. Iremos aprendiendo a usarla a lo largo de la asignatura. \n",
    "\n",
    "Hoy vamos a comenzar utilizando las funcionalidades relacionadas con la regresión lineal. Podéis consular toda la información en la siguiente URL: http://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "* Para ello hay que importar la clase LinearRegression del paquete linear_model ofrecido en scikit-learn (la librería se llama sklearn). \n",
    "* Una vez importada la clase debemos llamar al constructor para inicializar el modelo de regresión lineal. \n",
    "* Después hay que realizar el aprendizaje y para ello se utiliza la función fit, a la que se le pasan los datos de entrada (X) y las salidas correspondientes (y). Esta función automáticamente realiza el aprendizaje y modifica internamente los parámetros del modelo (intercept_ y coef_ para el término independiente y los $\\theta$ asociados a cada variable del problema).\n",
    "* Para clasificar nuevos datos tenemos dos opciones\n",
    "    * Utilizar intercept_ y coef_ aplicando la ecuación de la regresión lineal\n",
    "    * Utilizar la función predict, a la que se le pasa los datos de entrada de las instancias a predecir y devuelve las predicciones.\n",
    "\n",
    "En el código mostrado a continuación se ve un ejemplo del uso de esta librería con comentarios sobre qué se realiza en cada instrucción de código. Finalmente se muestra en una gráfica tanto la recta aprendida anteriormente como la recta aprendida con la librería scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b074df957b8e7067a055ba7d0f774ed6",
     "grade": false,
     "grade_id": "cell-87d90a291fd4a9ba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Se importa de la libreria scikit-learn de python (sklearn) el paquete correspondiente a la regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Se incializa el modelo llamando al constructor de la regresión lineal: todos los parámetros se asignan a sus valores por defecto\n",
    "regr = LinearRegression()\n",
    "# Se entrena el modelo (aprendizaje) utilizando la variable de entrada sin los unos X[:,1] y la variable de salida (y)\n",
    "# La función ravel devuelve una lista (si la entrada es una lista de listas coge todos los elementos y los almacena en la lista devuelta)\n",
    "# En la función reshape el valor -1 significa que el tamaño de esa dimensión se calcula automáticamente en base a la otra\n",
    "    # En este caso hacemos una columna de tantas filas como instancias tengan los datos\n",
    "regr.fit(X[:,1].reshape(-1,1), y.ravel())\n",
    "# Se evalúan los valores creados anteriormente para comparar ambos modelos aprendidos\n",
    "prediccionesOpcion1 = regr.intercept_+regr.coef_*xx\n",
    "prediccionesOpcion2 = regr.predict(xx.reshape(-1,1))\n",
    "plt.plot(xx, prediccionesOpcion2, label='Regresion lineal (Scikit-learn)')\n",
    "# Se muestra los datos a partir de los cuales se ha aprendido\n",
    "plt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\n",
    "# Se muestra la recta aprendida anteriormente para comparar\n",
    "plt.plot(xx,yy, label='Regresion lineal (Descenso por gradiente)')\n",
    "\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Numero de habitantes de las ciudades en decenas de miles.')\n",
    "plt.ylabel('Beneficio en decenas de miles de dolares.');\n",
    "plt.legend(loc=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "faaa2be8ea9c497c18b7474bf094f161",
     "grade": false,
     "grade_id": "cell-a8929ccbec1b29a5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Una vez aprendido el modelo de regresión lineal podemos utilizarlo para predecir datos que no han sido utilizados durante el entrenamiento. En este caso debéis predecir el valor de dos ciudades: la primera tiene 35.000 habitantes y la segunda 70.000 habitantes. Recordar que tanto el número de habitantes como el beneficio con el que se ha aprendido el modelo de regresión lineal está expresado en decenas de miles de habitantes.\n",
    "\n",
    "Predecir los beneficios de ambas ciudades utilizando los valores de los parámetros aprendidos por las funciones definidas por nosotros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03097ad13e4940feffc73056035b8eda",
     "grade": false,
     "grade_id": "cell-9edd08902ad7f747",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Predecir el beneficio para dos ciudades de 35000 y 70000 habitantes, respectivamente\n",
    "# ciudad1 = #<RELLENAR>\n",
    "# ciudad2 = #<RELLENAR>\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(ciudad1)\n",
    "print(ciudad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db99575659682333b2495851fd9811cc",
     "grade": true,
     "grade_id": "cell-830cd9802ce15742",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "assert_equal(round(ciudad1[0], 5), 4519.76787)\n",
    "assert_equal(round(ciudad2[0], 5), 45342.45013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4b2714107438da3e9f6910f05d85d69",
     "grade": false,
     "grade_id": "cell-44df92286c4bcba5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Finalmente, os dejamos un código que se utiliza para visualizar el comportamiento de la función de coste ($J$) en función de los parámetros del modelo ($\\theta_1$ y $\\theta_2$). Se crear dos gráficas, una para mostrar el comportamiento de la función de error en 3 dimensiones y la otra es una gráfica de contornos en la que se observa el nivel de error en cada punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "134fa64d3ab342b678f9a4487e3975ff",
     "grade": false,
     "grade_id": "cell-619189a47da022a8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Se crean 50 puntos en cada dimensión: en el rango [-10, 10] para la población y [-1, 4] para los beneficios\n",
    "B0 = np.linspace(-10, 10, 50)\n",
    "B1 = np.linspace(-1, 4, 50)\n",
    "# Se crean todas las combinaciones de valores de los puntos creados anteriormente\n",
    "xx, yy = np.meshgrid(B0, B1, indexing='xy')\n",
    "# Se crea una matriz donde vamos a almacenar el coste de la predicción (error) para cada combinación\n",
    "Z = np.zeros((B0.size,B1.size))\n",
    "\n",
    "# Se calcula el error de cada combinación\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "    Z[i,j] = computeCost(X,y, theta=[[xx[i,j]], [yy[i,j]]])\n",
    "\n",
    "# Se crea una figura con dos plots: uno para cada tipo de gráfico\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "# Gráfica de la izquierda: contornos (nivel de error)\n",
    "CS = ax1.contour(xx, yy, Z, np.logspace(-2, 3, 20), cmap=plt.cm.jet)\n",
    "ax1.scatter(theta[0],theta[1], c='r')\n",
    "\n",
    "# Gráfica de la izquierda: comportamiento de la función de coste\n",
    "ax2.plot_surface(xx, yy, Z, rstride=1, cstride=1, alpha=0.6, cmap=plt.cm.jet)\n",
    "ax2.set_zlabel('Coste')\n",
    "ax2.set_zlim(Z.min(),Z.max())\n",
    "ax2.view_init(elev=15, azim=230)\n",
    "\n",
    "# Se asignan las etiquetas de los ejes de las dos gráficas\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlabel(r'$\\theta_0$', fontsize=17)\n",
    "    ax.set_ylabel(r'$\\theta_1$', fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py37machlearn] *",
   "language": "python",
   "name": "conda-env-py37machlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
